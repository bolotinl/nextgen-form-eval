2022-07-01 19:26:46,588: Logging to /home/ottersloth/neuralhydrology/run_hourly/runs/fold_0_0107_192646/output.log initialized.
2022-07-01 19:26:46,589: ### Folder structure created at /home/ottersloth/neuralhydrology/run_hourly/runs/fold_0_0107_192646
2022-07-01 19:26:46,589: ### Run configurations for fold_0
2022-07-01 19:26:46,589: experiment_name: fold_0
2022-07-01 19:26:46,589: train_basin_file: Basin_CV_Splits/basins_train_0.txt
2022-07-01 19:26:46,589: validation_basin_file: 1_basin.txt
2022-07-01 19:26:46,589: test_basin_file: Basin_CV_Splits/basins_test_0.txt
2022-07-01 19:26:46,589: train_start_date: 1999-10-01 00:00:00
2022-07-01 19:26:46,589: train_end_date: 2005-09-30 00:00:00
2022-07-01 19:26:46,589: validation_start_date: 2004-10-01 00:00:00
2022-07-01 19:26:46,589: validation_end_date: 2006-09-30 00:00:00
2022-07-01 19:26:46,589: test_start_date: 2005-10-01 00:00:00
2022-07-01 19:26:46,589: test_end_date: 2011-09-30 00:00:00
2022-07-01 19:26:46,589: device: cpu
2022-07-01 19:26:46,589: validate_every: 10000
2022-07-01 19:26:46,589: validate_n_random_basins: 1
2022-07-01 19:26:46,589: metrics: ['NSE']
2022-07-01 19:26:46,589: model: cudalstm
2022-07-01 19:26:46,589: head: regression
2022-07-01 19:26:46,589: output_activation: linear
2022-07-01 19:26:46,589: hidden_size: 256
2022-07-01 19:26:46,590: initial_forget_bias: 3
2022-07-01 19:26:46,590: output_dropout: 0.4
2022-07-01 19:26:46,590: optimizer: Adam
2022-07-01 19:26:46,590: loss: NSE
2022-07-01 19:26:46,590: learning_rate: {0: 4e-05}
2022-07-01 19:26:46,590: batch_size: 256
2022-07-01 19:26:46,590: epochs: 5
2022-07-01 19:26:46,590: clip_gradient_norm: 1
2022-07-01 19:26:46,590: predict_last_n: 1
2022-07-01 19:26:46,590: seq_length: 4320
2022-07-01 19:26:46,590: num_workers: 8
2022-07-01 19:26:46,590: log_interval: 5
2022-07-01 19:26:46,590: log_tensorboard: True
2022-07-01 19:26:46,590: log_n_figures: 1
2022-07-01 19:26:46,590: save_weights_every: 1
2022-07-01 19:26:46,590: dataset: hourly_camels_us
2022-07-01 19:26:46,590: data_dir: /home/ottersloth/data/camels_hourly
2022-07-01 19:26:46,590: forcings: ['nldas_hourly']
2022-07-01 19:26:46,590: dynamic_inputs: ['total_precipitation', 'longwave_radiation', 'shortwave_radiation', 'pressure', 'specific_humidity', 'temperature', 'wind_u', 'wind_v']
2022-07-01 19:26:46,590: static_attributes: ['elev_mean', 'slope_mean', 'area_gages2', 'frac_forest', 'lai_max', 'lai_diff', 'gvf_max', 'gvf_diff', 'soil_depth_pelletier', 'soil_depth_statsgo', 'soil_porosity', 'soil_conductivity', 'max_water_content', 'sand_frac', 'silt_frac', 'clay_frac', 'carbonate_rocks_frac', 'geol_permeability', 'p_mean', 'pet_mean', 'aridity', 'frac_snow', 'high_prec_freq', 'high_prec_dur', 'low_prec_freq', 'low_prec_dur']
2022-07-01 19:26:46,590: target_variables: ['QObs_CAMELS(mm/h)']
2022-07-01 19:26:46,590: clip_targets_to_zero: ['QObs_CAMELS(mm/h)']
2022-07-01 19:26:46,590: number_of_basins: 477
2022-07-01 19:26:46,590: run_dir: /home/ottersloth/neuralhydrology/run_hourly/runs/fold_0_0107_192646
2022-07-01 19:26:46,591: train_dir: /home/ottersloth/neuralhydrology/run_hourly/runs/fold_0_0107_192646/train_data
2022-07-01 19:26:46,591: img_log_dir: /home/ottersloth/neuralhydrology/run_hourly/runs/fold_0_0107_192646/img_log
2022-07-01 19:26:46,591: ### Device cpu will be used for training
2022-07-01 19:26:46,793: Loading basin data into xarray data set.
2022-07-01 19:26:46,795: ## Warning: Hourly nldas_hourly NetCDF file not found. Falling back to slower csv files.
2022-07-01 19:26:50,242: Uncaught exception
Traceback (most recent call last):
  File "/home/ottersloth/anaconda3/bin/nh-run", line 33, in <module>
    sys.exit(load_entry_point('neuralhydrology', 'console_scripts', 'nh-run')())
  File "/home/ottersloth/neuralhydrology/neuralhydrology/nh_run.py", line 43, in _main
    start_run(config_file=Path(args["config_file"]), gpu=args["gpu"])
  File "/home/ottersloth/neuralhydrology/neuralhydrology/nh_run.py", line 76, in start_run
    start_training(config)
  File "/home/ottersloth/neuralhydrology/neuralhydrology/training/train.py", line 22, in start_training
    trainer.initialize_training()
  File "/home/ottersloth/neuralhydrology/neuralhydrology/training/basetrainer.py", line 162, in initialize_training
    ds = self._get_dataset()
  File "/home/ottersloth/neuralhydrology/neuralhydrology/training/basetrainer.py", line 79, in _get_dataset
    return get_dataset(cfg=self.cfg, period="train", is_train=True, scaler=self._scaler)
  File "/home/ottersloth/neuralhydrology/neuralhydrology/datasetzoo/__init__.py", line 80, in get_dataset
    ds = Dataset(cfg=cfg,
  File "/home/ottersloth/neuralhydrology/neuralhydrology/datasetzoo/hourlycamelsus.py", line 57, in __init__
    super(HourlyCamelsUS, self).__init__(cfg=cfg,
  File "/home/ottersloth/neuralhydrology/neuralhydrology/datasetzoo/camelsus.py", line 60, in __init__
    super(CamelsUS, self).__init__(cfg=cfg,
  File "/home/ottersloth/neuralhydrology/neuralhydrology/datasetzoo/basedataset.py", line 129, in __init__
    self._load_data()
  File "/home/ottersloth/neuralhydrology/neuralhydrology/datasetzoo/basedataset.py", line 597, in _load_data
    xr = self._load_or_create_xarray_dataset()
  File "/home/ottersloth/neuralhydrology/neuralhydrology/datasetzoo/basedataset.py", line 292, in _load_or_create_xarray_dataset
    df = self._load_basin_data(basin)
  File "/home/ottersloth/neuralhydrology/neuralhydrology/datasetzoo/hourlycamelsus.py", line 73, in _load_basin_data
    df = self.load_hourly_data(basin, forcing)
  File "/home/ottersloth/neuralhydrology/neuralhydrology/datasetzoo/hourlycamelsus.py", line 155, in load_hourly_data
    df = load_hourly_us_forcings(self.cfg.data_dir, basin, forcings)
  File "/home/ottersloth/neuralhydrology/neuralhydrology/datasetzoo/hourlycamelsus.py", line 195, in load_hourly_us_forcings
    return pd.read_csv(file_path, index_col=['date'], parse_dates=['date'])
  File "/home/ottersloth/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/ottersloth/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 680, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/ottersloth/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 581, in _read
    return parser.read(nrows)
  File "/home/ottersloth/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 1269, in read
    df = DataFrame(col_dict, columns=columns, index=index)
  File "/home/ottersloth/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py", line 636, in __init__
    mgr = dict_to_mgr(data, index, columns, dtype=dtype, copy=copy, typ=manager)
  File "/home/ottersloth/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py", line 502, in dict_to_mgr
    return arrays_to_mgr(arrays, columns, index, dtype=dtype, typ=typ, consolidate=copy)
  File "/home/ottersloth/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py", line 156, in arrays_to_mgr
    return create_block_manager_from_column_arrays(
  File "/home/ottersloth/anaconda3/lib/python3.9/site-packages/pandas/core/internals/managers.py", line 1954, in create_block_manager_from_column_arrays
    blocks = _form_blocks(arrays, consolidate)
  File "/home/ottersloth/anaconda3/lib/python3.9/site-packages/pandas/core/internals/managers.py", line 2028, in _form_blocks
    values, placement = _stack_arrays(list(tup_block), dtype)
  File "/home/ottersloth/anaconda3/lib/python3.9/site-packages/pandas/core/internals/managers.py", line 2069, in _stack_arrays
    stacked[i] = arr
KeyboardInterrupt
