{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe7ec2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESSENTIALS\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os\n",
    "from datetime import datetime\n",
    "\n",
    "# CLUSTERING AND RANDOM FOREST\n",
    "import skfuzzy as fuzz\n",
    "from sklearn import tree\n",
    "from sklearn import model_selection\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# DATA LIBRARIES\n",
    "# import rasterio\n",
    "# import contextily as cx\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import xarray\n",
    "from xarray.core.dataarray import DataArray\n",
    "\n",
    "\n",
    "# PREFERENCES\n",
    "pd.set_option('display.max_columns', 500)\n",
    "plt.rcParams['figure.dpi'] = 400\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df641318",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSelector():\n",
    "\n",
    "    def __init__(self, c_kwargs={}, rf_kwargs={}):\n",
    "       self.c_kwargs=c_kwargs        # CLUSTERING HYPERPARAMETERS\n",
    "       self.rf_kwargs=rf_kwargs      # RANDOM FOREST HYPERPARAMETERS\n",
    "       self.m = 2                    # EXPONENTIATION COEFFICIENT FOR CLUSTERING. TODO: MAKE ADJUSTABLE\n",
    "\n",
    "    def fuzzyCluster(self, data):\n",
    "        # Wraps Fuzzy Cluster function, only outputting percent belongs and formal cluster.\n",
    "\n",
    "        # CHECK THAT REQUIRED FIELDS ARE IN KWARGS, IF NOT ADD\n",
    "        if \"error\" not in self.c_kwargs:\n",
    "            self.c_kwargs['error']=0.005\n",
    "\n",
    "        if \"maxiter\" not in self.c_kwargs:\n",
    "            self.c_kwargs['maxiter']=1000\n",
    "\n",
    "        cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(data.T, self.n_centers, self.m, **self.c_kwargs)\n",
    "        label = np.argmax(u, axis=0)\n",
    "        return cntr, u, fpc, label\n",
    "\n",
    "    def howManyClusters(self, X, mintest=2,maxtest=15):\n",
    "        # Determines how many clusters should be used using the Fuzzy Partitions Coefficient (FPC)\n",
    "        # https://scikit-fuzzy.github.io/scikit-fuzzy/auto_examples/plot_cmeans.html#example-plot-cmeans-py\n",
    "        # TODO: FIGURE OUT IF THIS METHOD IS APPROPRIATE OR NOT\n",
    "        return 3\n",
    "        fpcs = []\n",
    "        listtests = np.arange(mintest,maxtest)\n",
    "        for ncenters in listtests:\n",
    "            self.n_centers = ncenters\n",
    "            _, _, fpc, _ = self.fuzzyCluster(X)\n",
    "            fpcs.append(fpc)\n",
    "        return listtests[np.argmax(fpcs)]\n",
    "\n",
    "    def train_rf(self, X_train, y_train, rf_controls={}):\n",
    "        # ADAPTED FROM https://stackoverflow.com/questions/28489667/combining-random-forest-models-in-scikit-learn\n",
    "\n",
    "        # RF CONTROLS PASSED DIRECTLY FROM PARAMETER, DEFAULT IS EMPTY\n",
    "        rf = RandomForestRegressor(**rf_controls) \n",
    "\n",
    "        # RF FITTING \n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        return rf\n",
    "\n",
    "    def fit(self, attributes, model_perf):\n",
    "\n",
    "        # CREATE RANDOM FOREST AND TRAIN\n",
    "        self.rf = self.train_rf(attributes, model_perf, rf_controls=self.rf_kwargs)\n",
    "        # print(r2_score(self.rf.predict(attributes), model_perf))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, attributes):\n",
    "\n",
    "        # CHECK WHETHER MODEL HAS BEEN TRAINED\n",
    "        if self.rf is None:\n",
    "            raise(Exception(\"ModelSelector isn't trained!\"))\n",
    "\n",
    "        # GET RANDOM FOREST PREDICTION\n",
    "        pred = self.rf.predict(attributes)\n",
    "\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dfb444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADAPTED FROM https://github.com/neuralhydrology/neuralhydrology/blob/1ff36ea8c8eff99ad25fa0f56f0119acbc9e6799/neuralhydrology/evaluation/metrics.py\n",
    "def nse(obs: DataArray, sim: DataArray) -> float:\n",
    "    denominator = ((obs - obs.mean())**2).sum()\n",
    "    numerator = ((sim - obs)**2).sum()\n",
    "    value = 1 - numerator / denominator\n",
    "    return float(value)\n",
    "\n",
    "def getFeatureImportance(selector, testidx, input, output, xx, reps=10):\n",
    "    # USING FULL PERMUTATION IMPORTANCE, AS OUTLINED IN \n",
    "    # https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "    result = permutation_importance(selector.rf, input.iloc[testidx, :], output.iloc[testidx], n_repeats=reps, random_state=42, n_jobs=2)\n",
    "    means = pd.Series(result.importances_mean, index=list(input)) \n",
    "    std = pd.Series(result.importances_std, index=list(input))\n",
    "    df = pd.concat([means, std], axis=1)\n",
    "    df.columns = [str(xx) + \"_mean\", str(xx) + \"_std\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def runFitMetric_getMSE(fitmet, rf_kwargs={}):\n",
    "    # FILEPATH TO SHAPEFILE CONTAINING CAMELS DATASET\n",
    "    # camelsdir = r\"C:\\Users\\franc\\OneDrive - University Of Houston\\000_SIResearch\\data\\HCDN_nhru_final\\HCDN_nhru_final_671.shp\"\n",
    "    camelsdir = r\"/home/ottersloth/ensemblennse/data/data/HCDN_nhru_final/HCDN_nhru_final_671.shp\"\n",
    "    \n",
    "    # DIRECTORY TO FOLDER CONTAINING CAMELS ATTRIBUTE TEXTFILES\n",
    "    # PRIOR TO THIS STEP MAKE SURE THE README IN THE FILE SYSTEM HAS BEEN REMOVED (or the file extension has been changed)\n",
    "    attdir = r\"/home/ottersloth/ensemblennse/data/data/camels_attributes_v2.0/camels_attributes_v2.0/\"\n",
    "\n",
    "    # READ CAMELS DATASET\n",
    "    camels = gpd.read_file(camelsdir)\n",
    "\n",
    "    # COPY TO KEEP ORIGINAL IN MEMORY\n",
    "    camels_df = camels \n",
    "\n",
    "    # LOOP THROUGH AND JOIN\n",
    "    filelist = glob.glob(attdir + \"*.txt\")\n",
    "    for i in filelist:\n",
    "        currdf = pd.read_csv(i, sep=\";\")\n",
    "        camels_df = camels_df.merge(currdf, how='left', left_on=\"hru_id\", right_on=\"gauge_id\")\n",
    "\n",
    "    # DEFINE WHAT WE WANT TO RUN ON\n",
    "    # perf_dir = r\"C:\\Users\\franc\\OneDrive - University Of Houston\\000_SIResearch\\data\\hourly_performances\\\\\"\n",
    "    perf_dir = r\"/home/ottersloth/ensemblennse/data/data/hourly_performances/\"\n",
    "    \n",
    "    perf_metrics = [fitmet]\n",
    "\n",
    "    # READ ALL CSV FILES IN DIRECTORY\n",
    "    os.chdir(perf_dir)\n",
    "    modelfiles = glob.glob(\"*.csv\")\n",
    "\n",
    "    # GET FIRST CSV FILE TO DEFINE DATAFRAME AND ADD PREFIX TO COLUMNS BASED ON NAME\n",
    "    print(perf_dir + modelfiles[0])\n",
    "    perf = pd.read_csv(perf_dir + modelfiles[0]).add_prefix(modelfiles[0][:-4] + \"_\")\n",
    "    # GET COLUMN NAME CONTAINING \"BASIN\"\n",
    "    fcol = [col for col in perf.columns if 'basin' in col]\n",
    "\n",
    "    # LOOP FOR EACH CSV FILE\n",
    "    for ii in range(1, len(modelfiles)):\n",
    "        print(perf_dir + modelfiles[ii])\n",
    "        # GET NEXT CSV FILE TO DEFINE DATAFRAME AND ADD PREFIX TO COLUMNS BASED ON NAME\n",
    "        currdf = pd.read_csv(perf_dir + modelfiles[ii]).add_prefix(modelfiles[ii][:-4] + \"_\")\n",
    "\n",
    "        # GET COLUMN NAME CONTAINING \"BASIN\"\n",
    "        basin_col= [col for col in currdf.columns if 'basin' in col]\n",
    "        # JOIN ON MATCHING BASINS\n",
    "        perf = perf.merge(currdf, how=\"inner\", left_on=fcol, right_on=basin_col)\n",
    "    \n",
    "    # GET COLUMN NAME CONTAINING \"FITMET\"\n",
    "    perf_met = [col for col in perf.columns if fitmet in col]\n",
    "\n",
    "    # CLEAN UP NONSENSICAL DATA (EG, BASIN LABELS)\n",
    "    # SO LETS GET A LIST OF VARIABLE NAMES WE WANT TO KEEP.\n",
    "\n",
    "    # TO START WE WILL KEEP THE SAME VARIABLES AS Kratzert et al. 2019, AS SHOWN BY OUR\n",
    "    # INTERNAL SPREADSHEET Attributes_CAMELS_vs_NHDPlus\n",
    "    varstokeep = ['organic_frac',\n",
    "    'elev_mean_x',\n",
    "    'slope_mean',\n",
    "    'area_gages2',\n",
    "    'soil_depth_pelletier',\n",
    "    'sand_frac',\n",
    "    'silt_frac',\n",
    "    'clay_frac',\n",
    "    'geol_permeability',\n",
    "    'p_mean',\n",
    "    'pet_mean',\n",
    "    'aridity',\n",
    "    'frac_snow',\n",
    "    'high_prec_freq',\n",
    "    'high_prec_dur',\n",
    "    'low_prec_freq',\n",
    "    'low_prec_dur']\n",
    "\n",
    "    camels_df = camels_df.merge(perf, how=\"inner\", left_on=\"hru_id\", right_on=fcol)\n",
    "    \n",
    "    inputdataset = camels_df[varstokeep]\n",
    "    outputdataset = camels_df[perf_met]\n",
    "    \n",
    "    \n",
    "    nsplits = 5\n",
    "    kf = KFold(n_splits=nsplits, shuffle=True)\n",
    "\n",
    "\n",
    "    testvalues = np.zeros((inputdataset.shape[0], outputdataset.shape[1]))                  # CONTAINER FOR PERFORMANCE VALUES WHEN BASIN IN TEST SET\n",
    "    modelno = 0                                                              # COUNTER FOR MODEL CONTAINER\n",
    "    test_modelno = np.zeros((inputdataset.shape[0], outputdataset.shape[1]))                # MODEL IN WHICH BASIN WAS IN TEST SET\n",
    "    test_modellist = list()                                                  # MODEL CONTAINER\n",
    "    featureimportance = list()\n",
    "    r2train = list()\n",
    "    r2test = list()\n",
    "    msetest = list()\n",
    "    msetrain = list()\n",
    "    msemeta = list()\n",
    "    trainlist_x = list()\n",
    "    trainlist_y = list()\n",
    "\n",
    "    currout=outputdataset\n",
    "\n",
    "    # KFOLD SPLIT OF DATASETS\n",
    "    for train, test in kf.split(inputdataset):            \n",
    "        # CODE FOR INDIVIDUAL MODEL TRAINING\n",
    "        for ii in range(currout.shape[1]):\n",
    "            # TRAIN MODEL ON TRAINING SET\n",
    "            model = None\n",
    "            model = ModelSelector(rf_kwargs=rf_kwargs)\n",
    "            model.fit(inputdataset.iloc[train, :], currout.iloc[train, ii])\n",
    "\n",
    "            # PERFORM PREDICTION ON TRAIN SET AND GET FIT METRICS\n",
    "            train_pred = model.predict(inputdataset.iloc[train, :])\n",
    "            trainrms = mse(train_pred, currout.iloc[train, ii].to_numpy())\n",
    "            trainr2 = r2_score(train_pred, currout.iloc[train, ii].to_numpy())\n",
    "\n",
    "            # PERFORM PREDICTION ON TEST SET AND GET FIT METRICS\n",
    "            model_pred = model.predict(inputdataset.iloc[test, :])\n",
    "            testrms = mse(model_pred, currout.iloc[test, ii].to_numpy())\n",
    "            testr2 = r2_score(model_pred, currout.iloc[test, ii].to_numpy())\n",
    "            \n",
    "            # GET FEATURE \n",
    "            fi = getFeatureImportance(model, test, inputdataset, currout.iloc[:,ii], modelno)\n",
    "            featureimportance.append(fi)\n",
    "\n",
    "            # SAVE VALUES IN CONTAINERS ABOVE\n",
    "            testvalues[test, ii] = model_pred\n",
    "            test_modelno[test, ii] = modelno\n",
    "            modelno = modelno + 1\n",
    "            test_modellist.append(model)\n",
    "            msetest.append(testrms)\n",
    "            msetrain.append(trainrms)\n",
    "            r2train.append(trainr2)\n",
    "            r2test.append(testr2)\n",
    "            trainlist_x.append(train_pred)\n",
    "            trainlist_y.append(outputdataset.iloc[train, :])\n",
    "\n",
    "            # print(f\"Test R2: {testr2:.3f} | Meta R2: {metar2:.3f} | Test MSE: {testrms:.3f} | Meta MSE: {metarms:.3f} | Model ID: {ii}\")\n",
    "\n",
    "    metrics = (r2train, r2test, msetrain, msetest)\n",
    "    trainlists = (trainlist_x, trainlist_y)\n",
    "    \n",
    "    return camels_df, inputdataset, outputdataset, testvalues, test_modelno, test_modellist, featureimportance, metrics, trainlists\n",
    "\n",
    "def softmax(x):\n",
    "    # ADAPTED FROM https://www.delftstack.com/howto/numpy/numpy-softmax/\n",
    "    maxx = np.max(x,axis=1,keepdims=True) #returns max of each row and keeps same dims\n",
    "    e_x = np.exp(x - maxx) #subtracts each row with its max value\n",
    "    sumx = np.sum(e_x,axis=1,keepdims=True) #returns sum of each row and keeps same dims\n",
    "    f_x = e_x / sumx \n",
    "    return f_x\n",
    "\n",
    "def ensemblePerf(perf, target, threshold=0.2, n=1, softmaxflag = False):\n",
    "    # TODO: CONSIDER DOING A MORE ROBUST THING WERE YOU CALCULATE THE DIFFERENCE\n",
    "    # BETWEEN EACH PERFORMANCE AND THE MINIMUM OF THE ROW WITHOUT ITSELF\n",
    "    # THEN, RUN A NP.WHERE TO ESTABLISH THAT IF BIGGER THAN THRESHOLD, SET TO NAN\n",
    "    # AND CALCULATE THE NORMALIZED PERFORMANCE FROM THERE, ONLY NECESSARY WITH MORE THAN\n",
    "    # 2 MODELS\n",
    "\n",
    "    # RANGE OF EACH ROW\n",
    "    rn = np.max(perf, axis=1) - np.min(perf, axis=1)\n",
    "    \n",
    "    # THIS IS THE BEST PREDICTED MODEL\n",
    "    # CALCULATED AS THE MAXIMUM OF THE PREDICTED PERFORMANCES\n",
    "    # BEST PRED MODEL = BPM\n",
    "    bpm_idx = np.argmax(perf, axis=1)\n",
    "    bpm_perf = perf[np.arange(perf.shape[0]), bpm_idx]\n",
    "\n",
    "    # CALCULATE THE VALUES FOR ENSEMBLING MODELS\n",
    "    \n",
    "    # EXPONENTIAL SETUP\n",
    "    if not softmaxflag:\n",
    "        perf_w = perf ** n\n",
    "        row_sums = perf_w.sum(axis=1)\n",
    "        perf_norm = perf_w / row_sums[:, np.newaxis]\n",
    "    else: \n",
    "        perf_norm = softmax(perf)\n",
    "    \n",
    "    ens_perf = np.sum(target * perf_norm, axis=1)\n",
    "\n",
    "    # THIS IS THE BEST ACTUAL MODEL\n",
    "    # CALCULATED AS THE MAXIMUM OF THE ACTUAL PERFORMANCES\n",
    "    # BEST ACTUAL MODEL = BAM\n",
    "    target_perf = target.to_numpy()\n",
    "    bam_idx = np.argmax(target_perf, axis=1)\n",
    "    bam_perf = target_perf[np.arange(perf.shape[0]), bam_idx]\n",
    "    \n",
    "    # CREATE OUTPUT STRUCTURE\n",
    "    output = np.where(rn < threshold, ens_perf, bam_perf)\n",
    "    exceed = np.where(rn > threshold, True, False)\n",
    "    \n",
    "    print(f\"Weighting in {perf.shape[0] - np.where(exceed)[0].shape[0]} basins\")\n",
    "    \n",
    "    perf_norm[exceed, :] = 0\n",
    "    perf_norm[np.where(exceed), bpm_idx[exceed]] = 1\n",
    "\n",
    "    return output, perf_norm\n",
    "\n",
    "def getLSTMTS(lstm_dir = '/home/ottersloth/neuralhydrology/nextgen-form-eval/run_hourly/runs/full_runs/runs/'):\n",
    "    file_list = os.listdir(lstm_dir)\n",
    "    file_list.remove('failed_runs')\n",
    "    file_list.remove('hydro_signatures')\n",
    "\n",
    "    num_files = len(file_list)\n",
    "\n",
    "    lstm_results = {}\n",
    "    lstm_results['basin_id'] = []\n",
    "    lstm_results['sim'] = []\n",
    "\n",
    "    for i in range(num_files): \n",
    "        lstm_test_dir = os.path.join(lstm_dir,file_list[i])\n",
    "        lstm_test_file = os.path.join(lstm_test_dir,\"test\", \"model_epoch003\",\"test_results.p\")\n",
    "        with open(lstm_test_file, \"rb\") as fp:\n",
    "            results = pickle.load(fp)\n",
    "\n",
    "        basin_id = [i for i in results.keys()]\n",
    "\n",
    "        for j in range(len(basin_id)):\n",
    "            sim = results[basin_id[j]]['1H']['xr']['QObs_CAMELS(mm/h)_sim'].values\n",
    "            sim = [float(sim[i]) for i in range(len(sim))]\n",
    "\n",
    "            lstm_results['sim'].append(sim)\n",
    "            lstm_results['basin_id'].append(basin_id[j])\n",
    "\n",
    "    df_lstm_results = pd.DataFrame(lstm_results)\n",
    "    return df_lstm_results\n",
    "\n",
    "def getWeightedFit(rfargs = {\"n_estimators\": 15}, weightparams={\"threshold\":0.2, \"n\":1, \"softmax\": False}):\n",
    "    \n",
    "    # RUN RF MODELS AND GET OUT OF BAG (OOB) \"TESTVALUES\"\n",
    "    camels_df, inputs, target, testvalues, test_modelno, test_modellist, featureimportance, metrics, trainlists = runFitMetric_getMSE(\"nnse\",rf_kwargs=rfargs)\n",
    "    outstruct_rf = (camels_df, inputs, target, testvalues, test_modelno, test_modellist, featureimportance, metrics, trainlists)\n",
    "    \n",
    "    # GET WEIGHTS FROM OOB TESTVALUES\n",
    "    _, weights = ensemblePerf(testvalues, target, **weightparams)\n",
    "    \n",
    "    # ADD WEIGHTS TO CAMELS AND DEFINE RUNNING DF \n",
    "    camels_df['weight_CFE'] = weights[:, 1]\n",
    "    camels_df['weight_LSTM'] = weights[:, 0]\n",
    "    weights_df = camels_df[['hru_id', 'weight_CFE', 'weight_LSTM']]\n",
    "    \n",
    "    # GET TIMSERIES OF LSTM RESULTS\n",
    "    df_lstm_results = getLSTMTS()\n",
    "    \n",
    "    # DEFINE DIR WITH ALL STREAMFLOW DATA \n",
    "    q_dir = \"/home/ottersloth/data/camels_hourly/usgs_streamflow\"\n",
    "\n",
    "    # TEST PERIOD\n",
    "    test_start=datetime.strptime(\"2002-09-30 23:00:00\", '%Y-%m-%d %H:%M:%S')\n",
    "    # ORIGINALLY UNTIL 11 PM, CHANGED BECAUSE COMPARISON FUNCTION IS INCLUSIVE LATER ON\n",
    "    test_end=datetime.strptime(\"2007-09-30 22:00:00\", '%Y-%m-%d %H:%M:%S') \n",
    "\n",
    "    # GET ALL CFE VALIDATION FILES \n",
    "    cfe_dir = \"/home/ottersloth/cfe_calibration/results/val_runs/\"\n",
    "    os.chdir(cfe_dir)\n",
    "    filelist = glob.glob(\"*.json\")\n",
    "\n",
    "    basinlist = list()\n",
    "    outnnselist = list()\n",
    "\n",
    "\n",
    "    for i in range(len(filelist)): \n",
    "\n",
    "        # GET FILE NAME FROM CONTAINER\n",
    "        file = filelist[i]\n",
    "\n",
    "        # GET BASIN ID BY SPLITTING FILENAME\n",
    "        basinid_raw = file.split(\"_\")[0]\n",
    "        basinid = '%08d' % int(basinid_raw) # ZERO PADDING\n",
    "\n",
    "        # GET TIMESERIES FROM LSTM DATAFRAME\n",
    "        match = df_lstm_results[df_lstm_results[\"basin_id\"] == basinid]\n",
    "\n",
    "        # SINCE NOT THE SAME BASINS WERE RUN, CHECK WE ACTUALLY GOT A MATCH\n",
    "        if match.shape[0] != 1:\n",
    "            print(f\"Skipping {basinid}\")\n",
    "            continue\n",
    "\n",
    "        # CONVERT TIMESERIES TO NP ARRAY\n",
    "        ts_lstm = np.array(match.iloc[0, 1])\n",
    "\n",
    "        # NOW READ CFE FILE\n",
    "        with open(file) as json_file:\n",
    "            data = json.load(json_file)\n",
    "\n",
    "        # CONVERT TIMESERIES TO NUMPY ARRAY\n",
    "        ts_cfe = np.array(data['validation sims'])\n",
    "\n",
    "        # GET MODEL WEIGHTS \n",
    "        weights = weights_df[weights_df[\"hru_id\"] == int(basinid)].to_numpy()\n",
    "        weights = weights[0][1:]\n",
    "\n",
    "        # weights = weights[1:]\n",
    "\n",
    "        # APPLY WEIGHTS\n",
    "        ts_final = (weights[0] * ts_cfe + weights[1] * ts_lstm)\n",
    "\n",
    "        # GET Q FROM USGS FOR TEST PERIOD\n",
    "        q_read = pd.read_csv(f\"{q_dir}/{basinid}-usgs-hourly.csv\")\n",
    "        q_read[\"datetime\"] = pd.to_datetime(q_read['date'], format='%Y-%m-%d %H:%M:%S') # CONVERT TO DATETIME\n",
    "        q_match = q_read[q_read.datetime.between(test_start, test_end)]\n",
    "        ts_q = q_match['QObs_CAMELS(mm/h)'].to_numpy()\n",
    "\n",
    "        # CALCULATE NSE \n",
    "        nse_calc = nse(ts_q, ts_final)\n",
    "\n",
    "        # CALCULATE NNSE\n",
    "        nnse = 1 / (2 - nse_calc)\n",
    "\n",
    "        # print(f\"{basinid} {nnse}\")\n",
    "        if i % 100 == 0:\n",
    "            print(f\"{i} / {len(filelist)}\")\n",
    "\n",
    "        # SAVE IN PROPER FORMAT\n",
    "        basinlist.append(basinid)\n",
    "        outnnselist.append(nnse)\n",
    "        \n",
    "    return basinlist, outnnselist, outstruct_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7ec4642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ottersloth/ensemblennse/data/data/hourly_performances/LSTM.csv\n",
      "/home/ottersloth/ensemblennse/data/data/hourly_performances/CFE.csv\n",
      "/home/ottersloth/ensemblennse/data/data/hourly_performances/nwm.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ottersloth/anaconda3/envs/ensemble/lib/python3.8/site-packages/geopandas/geodataframe.py:1483: FutureWarning: Passing 'suffixes' which cause duplicate columns {'gauge_id_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  result = DataFrame.merge(self, *args, **kwargs)\n",
      "/home/ottersloth/anaconda3/envs/ensemble/lib/python3.8/site-packages/geopandas/geodataframe.py:1483: FutureWarning: Passing 'suffixes' which cause duplicate columns {'gauge_id_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  result = DataFrame.merge(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighting in 253 basins\n",
      "0 / 495\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m basins, nnse, outstruct \u001b[38;5;241m=\u001b[39m \u001b[43mgetWeightedFit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrfargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_estimators\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweightparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreshold\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msoftmaxflag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m camels_df, inputdataset, outputdataset, testvalues, test_modelno, test_modellist, featureimportance, metrics, trainlists \u001b[38;5;241m=\u001b[39m outstruct\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mgetWeightedFit\u001b[0;34m(rfargs, weightparams)\u001b[0m\n\u001b[1;32m    311\u001b[0m ts_final \u001b[38;5;241m=\u001b[39m (weights[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m ts_cfe \u001b[38;5;241m+\u001b[39m weights[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m ts_lstm)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# GET Q FROM USGS FOR TEST PERIOD\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m q_read \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mq_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbasinid\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-usgs-hourly.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m q_read[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(q_read[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# CONVERT TO DATETIME\u001b[39;00m\n\u001b[1;32m    316\u001b[0m q_match \u001b[38;5;241m=\u001b[39m q_read[q_read\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mbetween(test_start, test_end)]\n",
      "File \u001b[0;32m~/anaconda3/envs/ensemble/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ensemble/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ensemble/lib/python3.8/site-packages/pandas/io/parsers/readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ensemble/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1255\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1253\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1255\u001b[0m     index, columns, col_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/ensemble/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 225\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    227\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/anaconda3/envs/ensemble/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ensemble/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:883\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ensemble/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1026\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ensemble/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1072\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ensemble/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1147\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ensemble/lib/python3.8/site-packages/pandas/core/dtypes/common.py:1429\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[38;5;66;03m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[1;32m   1421\u001b[0m     \u001b[38;5;66;03m#  here too.\u001b[39;00m\n\u001b[1;32m   1422\u001b[0m     \u001b[38;5;66;03m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;66;03m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1425\u001b[0m         dtype, (DatetimeTZDtype, PeriodDtype)\n\u001b[1;32m   1426\u001b[0m     )\n\u001b[0;32m-> 1429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   1430\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;124;03m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[1;32m   1432\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1472\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1474\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(arr_or_dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "basins, nnse, outstruct = getWeightedFit(rfargs = {\"n_estimators\": 15}, weightparams={\"threshold\":0.2, \"n\":1, \"softmaxflag\": False})\n",
    "\n",
    "camels_df, inputdataset, outputdataset, testvalues, test_modelno, test_modellist, featureimportance, metrics, trainlists = outstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d70c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 15)\n",
    "\n",
    "def getList(r):\n",
    "\n",
    "    features = featureimportance[0].shape[0] # NUMBER OF FEATURES\n",
    "    sum = np.zeros((features, ))\n",
    "    ss = np.zeros((features, ))\n",
    "    for i in r:\n",
    "        # POOL MEANS AND STANDARD DEVIATIONS:\n",
    "        # - GROUP MEAN IS MEAN OF ALL MEANS \n",
    "        # - GROUP STD IS DEFINED BY SQRT(SUM(STDs^2)), SINCE ALL SAMPLE SIZES ARE EQUAL\n",
    "        currdf = featureimportance[i]\n",
    "        sum = sum + currdf[str(i) + \"_mean\"].to_numpy().T\n",
    "        ss =  ss + currdf[str(i) + \"_std\"].to_numpy().T\n",
    "\n",
    "    means = sum / len(featureimportance)\n",
    "    std = np.sqrt(ss)  \n",
    "    \n",
    "    return np.abs(means)\n",
    "\n",
    "n_models = 2\n",
    "n_folds = 5\n",
    "topn = 5\n",
    "width = .4\n",
    "\n",
    "lstm = np.arange(0, n_models*n_folds, 2)\n",
    "cfe = np.arange(1, n_models*n_folds, 2)\n",
    "\n",
    "lstm_sc = getList(lstm)\n",
    "cfe_sc = getList(cfe)\n",
    "\n",
    "comb_imp = lstm_sc + cfe_sc\n",
    "ind = np.argsort(comb_imp)[-topn:]# np.argpartition(comb_imp, topn)[-topn:]\n",
    "\n",
    "other = np.arange(0, featureimportance[0].shape[0])\n",
    "other = other[np.logical_not(np.isin(other, ind))]\n",
    "\n",
    "x = np.arange(0, ind.shape[0]+1)\n",
    "\n",
    "figs, ax = plt.subplots()\n",
    "\n",
    "\n",
    "labels = np.array(list(featureimportance[0].index.values))\n",
    "labels = labels[ind]\n",
    "labels = np.insert(labels,  0, \"Other\")\n",
    "\n",
    "lstm_sc_t = lstm_sc[ind]\n",
    "cfe_sc_t = cfe_sc[ind]\n",
    "\n",
    "\n",
    "lstm_sc_t = np.insert(lstm_sc_t, 0, np.sum(lstm_sc[other]))\n",
    "cfe_sc_t = np.insert(cfe_sc_t, 0, np.sum(cfe_sc[other]))\n",
    "\n",
    "# NORMALIZE TO PERCENT\n",
    "cfe_sc_t = cfe_sc_t/cfe_sc_t.sum()\n",
    "lstm_sc_t = lstm_sc_t/lstm_sc_t.sum()\n",
    "\n",
    "\n",
    "rects1 = ax.barh(x - width, lstm_sc_t*100, width, label='LSTM')\n",
    "rects2 = ax.barh(x, cfe_sc_t*100, width, label='CFE')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_yticks(x, labels, fontsize=10)\n",
    "ax.set_xlabel(\"Perc. Variable Importance\")\n",
    "ax.set_ylim((-.5,topn+.5))\n",
    "#ax.set_xscale('log')\n",
    "ax.set_title(\"Variable Importance for Different Models via RF Permutation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecafa1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485d3c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = 2\n",
    "n_folds = 5\n",
    "topn = 5\n",
    "width = .4\n",
    "\n",
    "# -------------EXTREMELY IMPORTANT------------------------------------------- \n",
    "# DEFINE THE STARTING INDICES OF THESE LISTS AS THE SAME AS SHOWN IN THE CODE\n",
    "# BLOCK ABOVE (ie, FIRST COLUMN = 0)\n",
    "cfe_i = 1\n",
    "lstm_i = 0\n",
    "\n",
    "cfe_idx = np.arange(cfe_i, n_models*n_folds, 2)\n",
    "lstm_idx = np.arange(lstm_i, n_models*n_folds, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ff6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "\n",
    "def getList(r, ax, c, topn=5):\n",
    "\n",
    "    features = featureimportance[0].shape[0] # NUMBER OF FEATURES\n",
    "    sum = np.zeros((features, ))\n",
    "    ss = np.zeros((features, ))\n",
    "    for i in r:\n",
    "        # POOL MEANS AND STANDARD DEVIATIONS:\n",
    "        # - GROUP MEAN IS MEAN OF ALL MEANS \n",
    "        # - GROUP STD IS DEFINED BY SQRT(SUM(STDs^2)), SINCE ALL SAMPLE SIZES ARE EQUAL\n",
    "        currdf = featureimportance[i]\n",
    "        sum = sum + np.abs(currdf[str(i) + \"_mean\"].to_numpy()).T\n",
    "        ss =  ss + currdf[str(i) + \"_std\"].to_numpy().T\n",
    "\n",
    "    means = sum / len(featureimportance)\n",
    "    means = means/means.sum() * 100 # NORMALIZE TO PERCENT\n",
    "    \n",
    "    std = np.sqrt(ss)  \n",
    "    \n",
    "    ind = np.argsort(means)[-topn:]\n",
    "    \n",
    "    labels = featureimportance[0].index.values[ind]\n",
    "    selmeans = means[ind]\n",
    "    \n",
    "    # REVERSE TO SHOW IN DESCENDING ORDER\n",
    "    #selmeans = selmeans[::-1]\n",
    "    #labels = labels[::-1]\n",
    "    \n",
    "    ax.barh(np.arange(selmeans.shape[0]), selmeans, color=c)\n",
    "    ax.set_yticks(np.arange(selmeans.shape[0]))\n",
    "    ax.set_yticklabels(labels, fontsize=12)\n",
    "    ax.set_xlim((0, 75))\n",
    "    ax.set_xlabel(\"Perc. Variable Importance\")\n",
    "    \n",
    "    return ax\n",
    "\n",
    "\n",
    "figs, axs = plt.subplots(1,2, constrained_layout=True, facecolor=\"white\")\n",
    "\n",
    "figs.suptitle('Variable Importance via RFR Permutation (Top 5)', fontsize=18, x=0.6)\n",
    "axs[0] = getList(lstm_idx, axs[0], 'blue')\n",
    "axs[0].set_title(\"LSTM\")\n",
    "axs[1] = getList(cfe_idx, axs[1], 'red')\n",
    "axs[1].set_title(\"CFE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40ea52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_trainr2  = np.array(metrics[0])[lstm_idx]\n",
    "lstm_testr2   = np.array(metrics[1])[lstm_idx]\n",
    "lstm_trainmse = np.array(metrics[2])[lstm_idx]\n",
    "lstm_testmse  = np.array(metrics[3])[lstm_idx]\n",
    "\n",
    "\n",
    "cfe_trainr2  = np.array(metrics[0])[cfe_idx]\n",
    "cfe_testr2   = np.array(metrics[1])[cfe_idx]\n",
    "cfe_trainmse = np.array(metrics[2])[cfe_idx]\n",
    "cfe_testmse  = np.array(metrics[3])[cfe_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ff793f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prettify(ax, title, string):\n",
    "    props = dict(facecolor='white', alpha=0.5)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Prediction of NNSE\")\n",
    "    ax.set_ylabel(\"NNSE Value\")\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=.5, zorder=0)\n",
    "    ax.text(0.05, 0.95, string, transform=ax.transAxes, fontsize=10, verticalalignment='top', bbox=props, zorder=0)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    ax.grid()\n",
    "    return ax\n",
    "\n",
    "def getTrain(trainlists):\n",
    "    x, y = trainlists\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    x_cfe = x[cfe_idx,:].flatten()\n",
    "    y_cfe = y[cfe_idx,:,cfe_i].flatten()\n",
    "    \n",
    "    x_lstm = x[lstm_idx].flatten()\n",
    "    y_lstm = y[lstm_idx,:, lstm_i].flatten()\n",
    "    return x_cfe, y_cfe, x_lstm, y_lstm\n",
    "\n",
    "pred_cfe, true_cfe, pred_lstm, true_lstm = getTrain(trainlists)\n",
    "\n",
    "print(pred_cfe.shape)\n",
    "print(true_cfe.shape)\n",
    "\n",
    "cfestr = f\"Mean Train $R^2$: {cfe_trainr2.mean():.3f}\\nMean Test $R^2$: {cfe_testr2.mean():.3f}\\nMean Train RMSE: {np.sqrt(cfe_trainmse.mean()):.3f}\\nMean Test RMSE: {np.sqrt(cfe_testmse.mean()):.3f}\"\n",
    "lstmstr = f\"Mean Train $R^2$: {lstm_trainr2.mean():.3f}\\nMean Test $R^2$: {lstm_testr2.mean():.3f}\\nMean Train RMSE: {np.sqrt(lstm_trainmse.mean()):.3f}\\nMean Test RMSE: {np.sqrt(lstm_testmse.mean()):.3f}\"\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, constrained_layout=True, facecolor=\"white\")\n",
    "\n",
    "axs[0].scatter(pred_cfe, true_cfe, s=2, color=\"green\", alpha=.75, label=\"Training\")\n",
    "axs[0].scatter(testvalues[:, lstm_i], outputdataset['LSTM_nnse'], s=3, color=\"black\", label=\"Testing\")\n",
    "\n",
    "axs[1].scatter(pred_lstm, true_lstm, s=2, color=\"green\", alpha=.75, label=\"Training\")\n",
    "axs[1].scatter(testvalues[:, cfe_i], outputdataset['CFE_nnse'], s=3, color=\"black\", label=\"Testing\")\n",
    "\n",
    "\n",
    "axs[0] = prettify(axs[0], \"LSTM - RFR\", lstmstr)\n",
    "axs[1] = prettify(axs[1], \"CFE - RFR\", cfestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ef812",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "target = outputdataset\n",
    "\n",
    "# THIS IS THE BEST PREDICTED MODEL\n",
    "# CALCULATED AS THE MAXIMUM OF THE PREDICTED PERFORMANCES\n",
    "# BEST PRED MODEL = BPM\n",
    "bpm_idx = np.argmax(testvalues, axis=1)\n",
    "bpm_perf = testvalues[np.arange(testvalues.shape[0]), bpm_idx]\n",
    "\n",
    "# THIS IS THE BEST ACTUAL MODEL\n",
    "# CALCULATED AS THE MAXIMUM OF THE ACTUAL PERFORMANCES\n",
    "# BEST ACTUAL MODEL = BAM\n",
    "target_perf = target.to_numpy()\n",
    "bam_idx = np.argmax(target_perf, axis=1)\n",
    "bam_perf = target_perf[np.arange(testvalues.shape[0]), bam_idx]\n",
    "\n",
    "\n",
    "# ACTUAL MODEL PERFORMANCE = AMP\n",
    "amp = target.to_numpy()\n",
    "\n",
    "cfe = amp[:, cfe_i]\n",
    "cfe_est = testvalues[:, cfe_i]\n",
    "\n",
    "lstm = amp[:, lstm_i]\n",
    "lstm_est = testvalues[:, lstm_i]\n",
    "\n",
    "bestpred_est = testvalues[np.arange(amp.shape[0]), bpm_idx]\n",
    "bestpred_real = amp[np.arange(amp.shape[0]), bpm_idx]\n",
    "\n",
    "bestmodel = bam_perf\n",
    "\n",
    "# perf_models = [cfe_est, cfe, lstm_est, lstm, bestpred_est, bestpred_real, bestmodel]\n",
    "# labs = [\"CFE\\nRFR\", \"CFE\\nActual\", \"LSTM\\nRFR\",\"LSTM\\nActual\", \"BPM\\nRFR\", \"BPM\\nActual\", \"BAM\"]\n",
    "\n",
    "perf_models = [cfe, lstm, bestpred_real, bestmodel, nnse]\n",
    "labs = [\"CFE\", \"LSTM\", \"BPM\", \"BAM\", \"WE\"]\n",
    "\n",
    "plt.boxplot(perf_models, labels=labs, showmeans=True)\n",
    "plt.grid()\n",
    "plt.ylabel(\"NNSE\")\n",
    "plt.rcParams['figure.figsize'] = (10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea2f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "perf_models = [bestpred_real, bestmodel, nnse]\n",
    "labs = [\"BPM\", \"BAM\", \"Weighted Ensemble\"]\n",
    "# \n",
    "\n",
    "plt.boxplot(perf_models, labels=labs, showmeans=True)\n",
    "plt.ylabel(\"NNSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1949852",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_ensemble = pd.DataFrame(basins, columns=[\"basin_id\"])\n",
    "perf_ensemble[\"ensemble\"] = nnse\n",
    "\n",
    "\n",
    "bam_df = camels_df[[\"hru_id\"]].copy()\n",
    "bam_df['basin_id'] = bam_df['hru_id'].astype(str).str.zfill(8)\n",
    "bam_df[\"bam\"] = bam_perf\n",
    "bam_df[\"bpm\"] = bestpred_real\n",
    "\n",
    "perf_df = bam_df.merge(perf_ensemble, on=\"basin_id\")\n",
    "\n",
    "perf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7569b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = perf_df\n",
    "perf[\"ensemble_d\"] = perf[\"ensemble\"] - perf[\"bam\"]\n",
    "perf[\"ensemble_p\"] = perf[\"ensemble\"] - perf[\"bpm\"]\n",
    "plt.hist(perf[\"ensemble_d\"], bins=20)\n",
    "print(f'{perf[perf[\"ensemble_d\"] > 0].shape[0]} basins where ensemble outperformed BAM, {perf[perf[\"ensemble_p\"] > 0].shape[0]} where outperformed BPM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acab68a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(unique, counts) = np.unique(bpm_idx, return_counts=True)\n",
    "print(unique)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f4242",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(bam_idx, bpm_idx, normalize='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db75e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "miss = np.where(bpm_idx != bam_idx, True, False)\n",
    "diff = np.abs(target_perf[:,0] - target_perf[:,1])\n",
    "print(np.count_nonzero(np.logical_not(miss)))\n",
    "print(np.count_nonzero(miss))\n",
    "print(np.count_nonzero(diff[miss] < 0.2)/miss.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
