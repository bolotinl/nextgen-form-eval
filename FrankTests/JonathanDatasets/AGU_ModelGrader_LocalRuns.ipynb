{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d02d6fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESSENTIALS\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os\n",
    "from datetime import datetime\n",
    "\n",
    "# CLUSTERING AND RANDOM FOREST\n",
    "import skfuzzy as fuzz\n",
    "from sklearn import tree\n",
    "from sklearn import model_selection\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# DATA LIBRARIES\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import xarray\n",
    "from xarray.core.dataarray import DataArray\n",
    "\n",
    "\n",
    "# PREFERENCES\n",
    "pd.set_option('display.max_columns', 500)\n",
    "plt.rcParams['figure.dpi'] = 400\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe7ec2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = r\"C:/Users/franc/OneDrive - University Of Houston/000_SIResearch/data/\"\n",
    "\n",
    "remote = False\n",
    "if remote:\n",
    "    camels_dir = r\"/home/ottersloth/data/camels_hourly/\"\n",
    "    cfe_dir = r\"/home/ottersloth/cfe_calibration/\"\n",
    "    hrly_dir = r\"/home/ottersloth/ensemblennse/data/data/hourly_performances/\"\n",
    "    HCDN_dir = r\"/home/ottersloth/ensemblennse/data/data/HCDN_nhru_final/\"\n",
    "    camelsatt_dir = r\"/home/ottersloth/ensemblennse/data/data/camels_attributes_v2.0/camels_attributes_v2.0/\"\n",
    "    lstmruns_dir = r\"/home/ottersloth/neuralhydrology/nextgen-form-eval/run_hourly/runs/full_runs/\"\n",
    "    hrlyperf_dir = r\"/home/ottersloth/ensemblennse/data/data/hourly_performances/\"\n",
    "    cfeval_dir = r\"/home/ottersloth/cfe_calibration/results/val_runs/\"\n",
    "    nwm_dir = r\"/home/ottersloth/cfe_calibration/NWM_streamflow_results.csv\"\n",
    "    stream_dir = \"/home/ottersloth/data/camels_hourly/usgs_streamflow\"\n",
    "else:\n",
    "    base_dir = r\"C:/Users/franc/Downloads/dl/\"\n",
    "    data_dir = f\"{base_dir}/data/\"\n",
    "    camels_dir = base_dir\n",
    "    \n",
    "    cfe_dir = r\"/home/ottersloth/cfe_calibration/\"\n",
    "    hrly_dir = f\"{data_dir}hourly_performances/\"\n",
    "    HCDN_dir = f\"{data_dir}HCDN_nhru_final/\"\n",
    "    camelsatt_dir = f\"{data_dir}/camels_attributes_v2.0/camels_attributes_v2.0/\"\n",
    "    lstmruns_dir = f\"{base_dir}full_runs/\"\n",
    "    hrlyperf_dir = f\"{data_dir}hourly_performances/\"\n",
    "    cfeval_dir = f\"{base_dir}val_runs/\"\n",
    "    nwm_dir = f\"{base_dir}NWM_streamflow_results.csv\"\n",
    "    stream_dir = f\"{base_dir}usgs_streamflow\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f6c087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSelector():\n",
    "\n",
    "    def __init__(self, c_kwargs={}, rf_kwargs={}):\n",
    "       self.c_kwargs=c_kwargs        # CLUSTERING HYPERPARAMETERS\n",
    "       self.rf_kwargs=rf_kwargs      # RANDOM FOREST HYPERPARAMETERS\n",
    "       self.m = 2                    # EXPONENTIATION COEFFICIENT FOR CLUSTERING. TODO: MAKE ADJUSTABLE\n",
    "\n",
    "    def fuzzyCluster(self, data):\n",
    "        # Wraps Fuzzy Cluster function, only outputting percent belongs and formal cluster.\n",
    "\n",
    "        # CHECK THAT REQUIRED FIELDS ARE IN KWARGS, IF NOT ADD\n",
    "        if \"error\" not in self.c_kwargs:\n",
    "            self.c_kwargs['error']=0.005\n",
    "\n",
    "        if \"maxiter\" not in self.c_kwargs:\n",
    "            self.c_kwargs['maxiter']=1000\n",
    "\n",
    "        cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(data.T, self.n_centers, self.m, **self.c_kwargs)\n",
    "        label = np.argmax(u, axis=0)\n",
    "        return cntr, u, fpc, label\n",
    "\n",
    "    def howManyClusters(self, X, mintest=2,maxtest=15):\n",
    "        # Determines how many clusters should be used using the Fuzzy Partitions Coefficient (FPC)\n",
    "        # https://scikit-fuzzy.github.io/scikit-fuzzy/auto_examples/plot_cmeans.html#example-plot-cmeans-py\n",
    "        # TODO: FIGURE OUT IF THIS METHOD IS APPROPRIATE OR NOT\n",
    "        return 3\n",
    "        fpcs = []\n",
    "        listtests = np.arange(mintest,maxtest)\n",
    "        for ncenters in listtests:\n",
    "            self.n_centers = ncenters\n",
    "            _, _, fpc, _ = self.fuzzyCluster(X)\n",
    "            fpcs.append(fpc)\n",
    "        return listtests[np.argmax(fpcs)]\n",
    "\n",
    "    def train_rf(self, X_train, y_train, rf_controls={}):\n",
    "        # ADAPTED FROM https://stackoverflow.com/questions/28489667/combining-random-forest-models-in-scikit-learn\n",
    "\n",
    "        # RF CONTROLS PASSED DIRECTLY FROM PARAMETER, DEFAULT IS EMPTY\n",
    "        rf = RandomForestRegressor(**rf_controls) \n",
    "\n",
    "        # RF FITTING \n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        return rf\n",
    "\n",
    "    def fit(self, attributes, model_perf):\n",
    "\n",
    "        # CREATE RANDOM FOREST AND TRAIN\n",
    "        self.rf = self.train_rf(attributes, model_perf, rf_controls=self.rf_kwargs)\n",
    "        # print(r2_score(self.rf.predict(attributes), model_perf))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, attributes):\n",
    "\n",
    "        # CHECK WHETHER MODEL HAS BEEN TRAINED\n",
    "        if self.rf is None:\n",
    "            raise(Exception(\"ModelSelector isn't trained!\"))\n",
    "\n",
    "        # GET RANDOM FOREST PREDICTION\n",
    "        pred = self.rf.predict(attributes)\n",
    "\n",
    "\n",
    "        return pred\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df641318",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSelector():\n",
    "\n",
    "    def __init__(self, c_kwargs={}, rf_kwargs={}):\n",
    "       self.c_kwargs=c_kwargs        # CLUSTERING HYPERPARAMETERS\n",
    "       self.rf_kwargs=rf_kwargs      # RANDOM FOREST HYPERPARAMETERS\n",
    "       self.m = 2                    # EXPONENTIATION COEFFICIENT FOR CLUSTERING. TODO: MAKE ADJUSTABLE\n",
    "\n",
    "    def fuzzyCluster(self, data):\n",
    "        # Wraps Fuzzy Cluster function, only outputting percent belongs and formal cluster.\n",
    "\n",
    "        # CHECK THAT REQUIRED FIELDS ARE IN KWARGS, IF NOT ADD\n",
    "        if \"error\" not in self.c_kwargs:\n",
    "            self.c_kwargs['error']=0.005\n",
    "\n",
    "        if \"maxiter\" not in self.c_kwargs:\n",
    "            self.c_kwargs['maxiter']=1000\n",
    "\n",
    "        cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(data.T, self.n_centers, self.m, **self.c_kwargs)\n",
    "        label = np.argmax(u, axis=0)\n",
    "        return cntr, u, fpc, label\n",
    "\n",
    "    def howManyClusters(self, X, mintest=2,maxtest=15):\n",
    "        # Determines how many clusters should be used using the Fuzzy Partitions Coefficient (FPC)\n",
    "        # https://scikit-fuzzy.github.io/scikit-fuzzy/auto_examples/plot_cmeans.html#example-plot-cmeans-py\n",
    "        # TODO: FIGURE OUT IF THIS METHOD IS APPROPRIATE OR NOT\n",
    "        return 3\n",
    "        fpcs = []\n",
    "        listtests = np.arange(mintest,maxtest)\n",
    "        for ncenters in listtests:\n",
    "            self.n_centers = ncenters\n",
    "            _, _, fpc, _ = self.fuzzyCluster(X)\n",
    "            fpcs.append(fpc)\n",
    "        return listtests[np.argmax(fpcs)]\n",
    "\n",
    "    def train_rf(self, X_train, y_train, rf_controls={}):\n",
    "        # ADAPTED FROM https://stackoverflow.com/questions/28489667/combining-random-forest-models-in-scikit-learn\n",
    "\n",
    "        # RF CONTROLS PASSED DIRECTLY FROM PARAMETER, DEFAULT IS EMPTY\n",
    "        rf = RandomForestRegressor(**rf_controls) \n",
    "\n",
    "        # RF FITTING \n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        return rf\n",
    "\n",
    "    def fit(self, attributes, model_perf):\n",
    "\n",
    "        # CREATE RANDOM FOREST AND TRAIN\n",
    "        self.rf = self.train_rf(attributes, model_perf, rf_controls=self.rf_kwargs)\n",
    "        # print(r2_score(self.rf.predict(attributes), model_perf))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, attributes):\n",
    "\n",
    "        # CHECK WHETHER MODEL HAS BEEN TRAINED\n",
    "        if self.rf is None:\n",
    "            raise(Exception(\"ModelSelector isn't trained!\"))\n",
    "\n",
    "        # GET RANDOM FOREST PREDICTION\n",
    "        pred = self.rf.predict(attributes)\n",
    "\n",
    "\n",
    "        return pred\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70e7d12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADAPTED FROM https://github.com/neuralhydrology/neuralhydrology/blob/1ff36ea8c8eff99ad25fa0f56f0119acbc9e6799/neuralhydrology/evaluation/metrics.py\n",
    "def nse(obs: DataArray, sim: DataArray) -> float:\n",
    "    denominator = ((obs - obs.mean())**2).sum()\n",
    "    numerator = ((sim - obs)**2).sum()\n",
    "    value = 1 - numerator / denominator\n",
    "    return float(value)\n",
    "\n",
    "def getNNSEfromNWM():\n",
    "    \n",
    "    # DEFINE DIR WITH ALL STREAMFLOW DATA \n",
    "    # /home/ottersloth/data/camels_hourly/\n",
    "    q_dir = f\"{camels_dir}usgs_streamflow\"\n",
    "    \n",
    "    # TEST PERIOD\n",
    "    test_start=datetime.strptime(\"2002-09-30 23:00:00\", '%Y-%m-%d %H:%M:%S')\n",
    "    # ORIGINALLY UNTIL 11 PM, CHANGED BECAUSE COMPARISON FUNCTION IS INCLUSIVE LATER ON\n",
    "    test_end=datetime.strptime(\"2007-09-30 22:00:00\", '%Y-%m-%d %H:%M:%S') \n",
    "    \n",
    "    # DEFINE AND READ IN NWM TIMESERIES\n",
    "    nwmdir = f\"{cfe_dir}NWM_streamflow_results.csv\"\n",
    "    nwm = pd.read_csv(nwmdir)\n",
    "    \n",
    "    # GET BASINS IN DATASET, REMOVE FIRST COLUMN NAME BC IT'S D\n",
    "    basins = nwm.columns.to_list()[1:]\n",
    "    \n",
    "    # CONTAINER FOR OUTPUT\n",
    "    nnsedf = list()\n",
    "    \n",
    "    # LOOP THROUGH BASINS IN DATASET\n",
    "    for currbasin in basins:\n",
    "        try:\n",
    "        \n",
    "            basinid = currbasin\n",
    "\n",
    "            # GET MODEL PREDICTION IN CURRENT BASINS\n",
    "            pred = nwm[currbasin].to_numpy()\n",
    "\n",
    "            # GET Q FROM USGS FOR TEST PERIOD\n",
    "            q_read = pd.read_csv(f\"{q_dir}/{basinid}-usgs-hourly.csv\")\n",
    "            q_read[\"datetime\"] = pd.to_datetime(q_read['date'], format='%Y-%m-%d %H:%M:%S') # CONVERT TO DATETIME\n",
    "            q_match = q_read[q_read.datetime.between(test_start, test_end)]\n",
    "            ts_q = q_match['QObs_CAMELS(mm/h)'].to_numpy()\n",
    "\n",
    "            # CALCULATE NSE \n",
    "            nse_calc = nse(ts_q, pred)\n",
    "\n",
    "            # CALCULATE NNSE\n",
    "            nnse = 1 / (2 - nse_calc)\n",
    "\n",
    "            # APPEND TO CONTAINER\n",
    "            # df_add = {currbasin: nnse}\n",
    "            df_add = list(np.array([currbasin, nnse]))\n",
    "            \n",
    "            nnsedf.append(df_add)\n",
    "            print(df_add)\n",
    "            \n",
    "        \n",
    "        except: \n",
    "            continue\n",
    "            \n",
    "    nnsedf = pd.DataFrame(np.array(nnsedf), columns=[\"basin_id\", \"nnse\"])\n",
    "    nnsedf.to_csv(f\"{hrly_dir}nwm.csv\")\n",
    "    \n",
    "    \n",
    "    return nnsedf\n",
    "\n",
    "# nwm_nnse = getNNSEfromNWM()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dfb444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureImportance(selector, testidx, input, output, xx, reps=10):\n",
    "    # USING FULL PERMUTATION IMPORTANCE, AS OUTLINED IN \n",
    "    # https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "    result = permutation_importance(selector.rf, input.iloc[testidx, :], output.iloc[testidx], n_repeats=reps, random_state=42, n_jobs=2)\n",
    "    means = pd.Series(result.importances_mean, index=list(input)) \n",
    "    std = pd.Series(result.importances_std, index=list(input))\n",
    "    df = pd.concat([means, std], axis=1)\n",
    "    df.columns = [str(xx) + \"_mean\", str(xx) + \"_std\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def runFitMetric_getMSE(fitmet, rf_kwargs={}):\n",
    "    # FILEPATH TO SHAPEFILE CONTAINING CAMELS DATASET\n",
    "    # camelsdir = r\"C:\\Users\\franc\\OneDrive - University Of Houston\\000_SIResearch\\data\\HCDN_nhru_final\\HCDN_nhru_final_671.shp\"\n",
    "    camelsdir = f\"{HCDN_dir}HCDN_nhru_final_671.shp\"\n",
    "    \n",
    "    # DIRECTORY TO FOLDER CONTAINING CAMELS ATTRIBUTE TEXTFILES\n",
    "    # PRIOR TO THIS STEP MAKE SURE THE README IN THE FILE SYSTEM HAS BEEN REMOVED (or the file extension has been changed)\n",
    "    attdir = camelsatt_dir\n",
    "\n",
    "    # READ CAMELS DATASET\n",
    "    camels = gpd.read_file(camelsdir)\n",
    "\n",
    "    # COPY TO KEEP ORIGINAL IN MEMORY\n",
    "    camels_df = camels \n",
    "\n",
    "    # LOOP THROUGH AND JOIN\n",
    "    filelist = glob.glob(attdir + \"*.txt\")\n",
    "    for i in filelist:\n",
    "        currdf = pd.read_csv(i, sep=\";\")\n",
    "        camels_df = camels_df.merge(currdf, how='left', left_on=\"hru_id\", right_on=\"gauge_id\")\n",
    "\n",
    "    # DEFINE WHAT WE WANT TO RUN ON\n",
    "    # perf_dir = r\"C:\\Users\\franc\\OneDrive - University Of Houston\\000_SIResearch\\data\\hourly_performances\\\\\"\n",
    "    perf_dir = hrlyperf_dir\n",
    "    \n",
    "    perf_metrics = [fitmet]\n",
    "\n",
    "    # READ ALL CSV FILES IN DIRECTORY\n",
    "    os.chdir(perf_dir)\n",
    "    modelfiles = glob.glob(\"*.csv\")\n",
    "\n",
    "    # GET FIRST CSV FILE TO DEFINE DATAFRAME AND ADD PREFIX TO COLUMNS BASED ON NAME\n",
    "    print(perf_dir + modelfiles[0])\n",
    "    perf = pd.read_csv(perf_dir + modelfiles[0]).add_prefix(modelfiles[0][:-4] + \"_\")\n",
    "    # GET COLUMN NAME CONTAINING \"BASIN\"\n",
    "    fcol = [col for col in perf.columns if 'basin' in col]\n",
    "\n",
    "    # LOOP FOR EACH CSV FILE\n",
    "    for ii in range(1, len(modelfiles)):\n",
    "        print(perf_dir + modelfiles[ii])\n",
    "        # GET NEXT CSV FILE TO DEFINE DATAFRAME AND ADD PREFIX TO COLUMNS BASED ON NAME\n",
    "        currdf = pd.read_csv(perf_dir + modelfiles[ii]).add_prefix(modelfiles[ii][:-4] + \"_\")\n",
    "\n",
    "        # GET COLUMN NAME CONTAINING \"BASIN\"\n",
    "        basin_col= [col for col in currdf.columns if 'basin' in col]\n",
    "        # JOIN ON MATCHING BASINS\n",
    "        perf = perf.merge(currdf, how=\"inner\", left_on=fcol, right_on=basin_col)\n",
    "    \n",
    "    # GET COLUMN NAME CONTAINING \"FITMET\"\n",
    "    perf_met = [col for col in perf.columns if fitmet in col]\n",
    "\n",
    "    # CLEAN UP NONSENSICAL DATA (EG, BASIN LABELS)\n",
    "    # SO LETS GET A LIST OF VARIABLE NAMES WE WANT TO KEEP.\n",
    "\n",
    "    # TO START WE WILL KEEP THE SAME VARIABLES AS Kratzert et al. 2019, AS SHOWN BY OUR\n",
    "    # INTERNAL SPREADSHEET Attributes_CAMELS_vs_NHDPlus\n",
    "    varstokeep = ['organic_frac',\n",
    "    'elev_mean_x',\n",
    "    'slope_mean',\n",
    "    'area_gages2',\n",
    "    'soil_depth_pelletier',\n",
    "    'sand_frac',\n",
    "    'silt_frac',\n",
    "    'clay_frac',\n",
    "    'geol_permeability',\n",
    "    'p_mean',\n",
    "    'pet_mean',\n",
    "    'aridity',\n",
    "    'frac_snow',\n",
    "    'high_prec_freq',\n",
    "    'high_prec_dur',\n",
    "    'low_prec_freq',\n",
    "    'low_prec_dur']\n",
    "\n",
    "    camels_df = camels_df.merge(perf, how=\"inner\", left_on=\"hru_id\", right_on=fcol)\n",
    "    \n",
    "    inputdataset = camels_df[varstokeep]\n",
    "    outputdataset = camels_df[perf_met]\n",
    "    \n",
    "    \n",
    "    nsplits = 5\n",
    "    kf = KFold(n_splits=nsplits, shuffle=True)\n",
    "\n",
    "\n",
    "    testvalues = np.zeros((inputdataset.shape[0], outputdataset.shape[1]))                  # CONTAINER FOR PERFORMANCE VALUES WHEN BASIN IN TEST SET\n",
    "    modelno = 0                                                              # COUNTER FOR MODEL CONTAINER\n",
    "    test_modelno = np.zeros((inputdataset.shape[0], outputdataset.shape[1]))                # MODEL IN WHICH BASIN WAS IN TEST SET\n",
    "    test_modellist = list()                                                  # MODEL CONTAINER\n",
    "    featureimportance = list()\n",
    "    r2train = list()\n",
    "    r2test = list()\n",
    "    msetest = list()\n",
    "    msetrain = list()\n",
    "    msemeta = list()\n",
    "    trainlist_x = list()\n",
    "    trainlist_y = list()\n",
    "\n",
    "    currout=outputdataset\n",
    "\n",
    "    # KFOLD SPLIT OF DATASETS\n",
    "    for train, test in kf.split(inputdataset):            \n",
    "        # CODE FOR INDIVIDUAL MODEL TRAINING\n",
    "        for ii in range(currout.shape[1]):\n",
    "            # TRAIN MODEL ON TRAINING SET\n",
    "            model = None\n",
    "            model = ModelSelector(rf_kwargs=rf_kwargs)\n",
    "            model.fit(inputdataset.iloc[train, :], currout.iloc[train, ii])\n",
    "\n",
    "            # PERFORM PREDICTION ON TRAIN SET AND GET FIT METRICS\n",
    "            train_pred = model.predict(inputdataset.iloc[train, :])\n",
    "            trainrms = mse(train_pred, currout.iloc[train, ii].to_numpy())\n",
    "            trainr2 = r2_score(train_pred, currout.iloc[train, ii].to_numpy())\n",
    "\n",
    "            # PERFORM PREDICTION ON TEST SET AND GET FIT METRICS\n",
    "            model_pred = model.predict(inputdataset.iloc[test, :])\n",
    "            testrms = mse(model_pred, currout.iloc[test, ii].to_numpy())\n",
    "            testr2 = r2_score(model_pred, currout.iloc[test, ii].to_numpy())\n",
    "            \n",
    "            # GET FEATURE \n",
    "            fi = getFeatureImportance(model, test, inputdataset, currout.iloc[:,ii], modelno)\n",
    "            featureimportance.append(fi)\n",
    "\n",
    "            # SAVE VALUES IN CONTAINERS ABOVE\n",
    "            testvalues[test, ii] = model_pred\n",
    "            test_modelno[test, ii] = modelno\n",
    "            modelno = modelno + 1\n",
    "            test_modellist.append(model)\n",
    "            msetest.append(testrms)\n",
    "            msetrain.append(trainrms)\n",
    "            r2train.append(trainr2)\n",
    "            r2test.append(testr2)\n",
    "            trainlist_x.append(train_pred)\n",
    "            trainlist_y.append(outputdataset.iloc[train, :])\n",
    "\n",
    "            # print(f\"Test R2: {testr2:.3f} | Meta R2: {metar2:.3f} | Test MSE: {testrms:.3f} | Meta MSE: {metarms:.3f} | Model ID: {ii}\")\n",
    "\n",
    "    metrics = (r2train, r2test, msetrain, msetest)\n",
    "    trainlists = (trainlist_x, trainlist_y)\n",
    "    \n",
    "    return camels_df, inputdataset, outputdataset, testvalues, test_modelno, test_modellist, featureimportance, metrics, trainlists\n",
    "\n",
    "def softmax(x):\n",
    "    # ADAPTED FROM https://www.delftstack.com/howto/numpy/numpy-softmax/\n",
    "    maxx = np.max(x,axis=1,keepdims=True) #returns max of each row and keeps same dims\n",
    "    e_x = np.exp(x - maxx) #subtracts each row with its max value\n",
    "    sumx = np.sum(e_x,axis=1,keepdims=True) #returns sum of each row and keeps same dims\n",
    "    f_x = e_x / sumx \n",
    "    return f_x\n",
    "\n",
    "def ensemblePerf(perf, target, threshold=0.2, n=1, softmaxflag = False):\n",
    "    # TODO: CONSIDER DOING A MORE ROBUST THING WERE YOU CALCULATE THE DIFFERENCE\n",
    "    # BETWEEN EACH PERFORMANCE AND THE MINIMUM OF THE ROW WITHOUT ITSELF\n",
    "    # THEN, RUN A NP.WHERE TO ESTABLISH THAT IF BIGGER THAN THRESHOLD, SET TO NAN\n",
    "    # AND CALCULATE THE NORMALIZED PERFORMANCE FROM THERE, ONLY NECESSARY WITH MORE THAN\n",
    "    # 2 MODELS\n",
    "\n",
    "    # RANGE OF EACH ROW\n",
    "    rn = np.max(perf, axis=1) - np.min(perf, axis=1)\n",
    "    \n",
    "    # THIS IS THE BEST PREDICTED MODEL\n",
    "    # CALCULATED AS THE MAXIMUM OF THE PREDICTED PERFORMANCES\n",
    "    # BEST PRED MODEL = BPM\n",
    "    bpm_idx = np.argmax(perf, axis=1)\n",
    "    bpm_perf = perf[np.arange(perf.shape[0]), bpm_idx]\n",
    "\n",
    "    # CALCULATE THE VALUES FOR ENSEMBLING MODELS\n",
    "    \n",
    "    # EXPONENTIAL SETUP\n",
    "    if not softmaxflag:\n",
    "        perf_w = perf ** n\n",
    "        row_sums = perf_w.sum(axis=1)\n",
    "        perf_norm = perf_w / row_sums[:, np.newaxis]\n",
    "    else: \n",
    "        perf_norm = softmax(perf)\n",
    "    \n",
    "    ens_perf = np.sum(target * perf_norm, axis=1)\n",
    "\n",
    "    # THIS IS THE BEST ACTUAL MODEL\n",
    "    # CALCULATED AS THE MAXIMUM OF THE ACTUAL PERFORMANCES\n",
    "    # BEST ACTUAL MODEL = BAM\n",
    "    target_perf = target.to_numpy()\n",
    "    bam_idx = np.argmax(target_perf, axis=1)\n",
    "    bam_perf = target_perf[np.arange(perf.shape[0]), bam_idx]\n",
    "    \n",
    "    # CREATE OUTPUT STRUCTURE\n",
    "    output = np.where(rn < threshold, ens_perf, bam_perf)\n",
    "    return output, perf_norm\n",
    "\n",
    "def ensemblePerf(perf, target, threshold=0.2, n=1, softmaxflag = False):\n",
    "    # TODO: CONSIDER DOING A MORE ROBUST THING WERE YOU CALCULATE THE DIFFERENCE\n",
    "    # BETWEEN EACH PERFORMANCE AND THE MINIMUM OF THE ROW WITHOUT ITSELF\n",
    "    # THEN, RUN A NP.WHERE TO ESTABLISH THAT IF BIGGER THAN THRESHOLD, SET TO NAN\n",
    "    # AND CALCULATE THE NORMALIZED PERFORMANCE FROM THERE, ONLY NECESSARY WITH MORE THAN\n",
    "    # 2 MODELS\n",
    "\n",
    "    # RANGE OF EACH ROW\n",
    "    rn = np.max(perf, axis=1, keepdims=True) - perf\n",
    "\n",
    "    # CALCULATE THE VALUES FOR ENSEMBLING MODELS\n",
    "    \n",
    "    # EXPONENTIAL SETUP\n",
    "    if not softmaxflag:\n",
    "        perf_w = perf ** n\n",
    "        perf_w = np.where(rn > threshold, 0, perf_w)\n",
    "        row_sums = perf_w.sum(axis=1)\n",
    "        perf_norm = perf_w / row_sums[:, np.newaxis]\n",
    "    else: \n",
    "        perf = np.where(rn > threshold, 0, perf)\n",
    "        perf_norm = softmax(perf)\n",
    "    \n",
    "    n_weighting = np.count_nonzero(np.any(perf_norm == 1, axis=1))\n",
    "    n_partialweighting = np.count_nonzero(np.any(perf_norm == 0, axis=1))\n",
    "    n_total = perf_norm.shape[0]\n",
    "    print(f\"Not weighting in {n_weighting} of {n_total} basins, partial weighting in {n_partialweighting - n_weighting}\")\n",
    "    \n",
    "    return perf_norm\n",
    "\n",
    "\n",
    "\n",
    "def getLSTMTS(lstm_dir = f'{lstmruns_dir}runs/'):\n",
    "    file_list = os.listdir(lstm_dir)\n",
    "    file_list.remove('failed_runs')\n",
    "    file_list.remove('hydro_signatures')\n",
    "\n",
    "    num_files = len(file_list)\n",
    "\n",
    "    lstm_results = {}\n",
    "    lstm_results['basin_id'] = []\n",
    "    lstm_results['sim'] = []\n",
    "\n",
    "    for i in range(num_files): \n",
    "        lstm_test_dir = os.path.join(lstm_dir,file_list[i])\n",
    "        lstm_test_file = os.path.join(lstm_test_dir,\"test\", \"model_epoch003\",\"test_results.p\")\n",
    "        with open(lstm_test_file, \"rb\") as fp:\n",
    "            results = pickle.load(fp)\n",
    "\n",
    "        basin_id = [i for i in results.keys()]\n",
    "\n",
    "        for j in range(len(basin_id)):\n",
    "            sim = results[basin_id[j]]['1H']['xr']['QObs_CAMELS(mm/h)_sim'].values\n",
    "            sim = [float(sim[i]) for i in range(len(sim))]\n",
    "\n",
    "            lstm_results['sim'].append(sim)\n",
    "            lstm_results['basin_id'].append(basin_id[j])\n",
    "\n",
    "    df_lstm_results = pd.DataFrame(lstm_results)\n",
    "    return df_lstm_results\n",
    "\n",
    "def getWeightedFit(rfargs = {\"n_estimators\": 15}, weightparams={\"threshold\":0.2, \"n\":1, \"softmax\": False}):\n",
    "    \n",
    "    # RUN RF MODELS AND GET OUT OF BAG (OOB) \"TESTVALUES\"\n",
    "    camels_df, inputs, target, testvalues, test_modelno, test_modellist, featureimportance, metrics, trainlists = runFitMetric_getMSE(\"nnse\",rf_kwargs=rfargs)\n",
    "    outstruct_rf = (camels_df, inputs, target, testvalues, test_modelno, test_modellist, featureimportance, metrics, trainlists)\n",
    "    \n",
    "    # GET WEIGHTS FROM OOB TESTVALUES\n",
    "    weights = ensemblePerf(testvalues, target, **weightparams)\n",
    "    \n",
    "    # ADD WEIGHTS TO CAMELS AND DEFINE RUNNING DF \n",
    "    camels_df['weight_CFE'] = weights[:, 0]\n",
    "    camels_df['weight_LSTM'] = weights[:, 1]\n",
    "    camels_df['weight_NWM'] = weights[:, 2]\n",
    "    weights_df = camels_df[['hru_id', 'weight_CFE', 'weight_LSTM', 'weight_NWM']]\n",
    "    \n",
    "    # GET TIMSERIES OF LSTM RESULTS\n",
    "    df_lstm_results = getLSTMTS()\n",
    "    \n",
    "    # DEFINE DIR WITH ALL STREAMFLOW DATA \n",
    "    q_dir = stream_dir\n",
    "\n",
    "    # TEST PERIOD\n",
    "    test_start=datetime.strptime(\"2002-09-30 23:00:00\", '%Y-%m-%d %H:%M:%S')\n",
    "    # ORIGINALLY UNTIL 11 PM, CHANGED BECAUSE COMPARISON FUNCTION IS INCLUSIVE LATER ON\n",
    "    test_end=datetime.strptime(\"2007-09-30 22:00:00\", '%Y-%m-%d %H:%M:%S') \n",
    "\n",
    "    # GET ALL CFE VALIDATION FILES \n",
    "    cfe_dir = cfeval_dir\n",
    "    os.chdir(cfe_dir)\n",
    "    filelist = glob.glob(\"*.json\")\n",
    "    \n",
    "    # GET NWM FILES\n",
    "    nwmdir = nwm_dir\n",
    "    nwm = pd.read_csv(nwmdir)\n",
    "\n",
    "    basinlist = list()\n",
    "    outnnselist = list()\n",
    "\n",
    "\n",
    "    for i in range(len(filelist)): \n",
    "\n",
    "        # GET FILE NAME FROM CONTAINER\n",
    "        file = filelist[i]\n",
    "\n",
    "        # GET BASIN ID BY SPLITTING FILENAME\n",
    "        basinid_raw = file.split(\"_\")[0]\n",
    "        basinid = '%08d' % int(basinid_raw) # ZERO PADDING\n",
    "\n",
    "        # GET TIMESERIES FROM LSTM DATAFRAME\n",
    "        match = df_lstm_results[df_lstm_results[\"basin_id\"] == basinid]\n",
    "\n",
    "        # SINCE NOT THE SAME BASINS WERE RUN, CHECK WE ACTUALLY GOT A MATCH\n",
    "        if match.shape[0] != 1:\n",
    "            print(f\"Skipping {basinid}\")\n",
    "            continue\n",
    "\n",
    "        # CONVERT TIMESERIES TO NP ARRAY\n",
    "        ts_lstm = np.array(match.iloc[0, 1])\n",
    "\n",
    "        # NOW READ CFE FILE\n",
    "        with open(file) as json_file:\n",
    "            data = json.load(json_file)\n",
    "\n",
    "        # CONVERT TIMESERIES TO NUMPY ARRAY\n",
    "        ts_cfe = np.array(data['validation sims'])\n",
    "        \n",
    "        # GET NWM TIMESERIES\n",
    "        ts_nwm = nwm[basinid].to_numpy()\n",
    "\n",
    "        # GET MODEL WEIGHTS \n",
    "        weights = weights_df[weights_df[\"hru_id\"] == int(basinid)].to_numpy()\n",
    "        weights = weights[0][1:]\n",
    "\n",
    "        # weights = weights[1:]\n",
    "\n",
    "        # APPLY WEIGHTS\n",
    "        ts_final = (weights[0] * ts_cfe + weights[1] * ts_lstm  + weights[2] * ts_nwm)\n",
    "\n",
    "        # GET Q FROM USGS FOR TEST PERIOD\n",
    "        q_read = pd.read_csv(f\"{q_dir}/{basinid}-usgs-hourly.csv\")\n",
    "        q_read[\"datetime\"] = pd.to_datetime(q_read['date'], format='%Y-%m-%d %H:%M:%S') # CONVERT TO DATETIME\n",
    "        q_match = q_read[q_read.datetime.between(test_start, test_end)]\n",
    "        ts_q = q_match['QObs_CAMELS(mm/h)'].to_numpy()\n",
    "\n",
    "        # CALCULATE NSE \n",
    "        nse_calc = nse(ts_q, ts_final)\n",
    "\n",
    "        # CALCULATE NNSE\n",
    "        nnse = 1 / (2 - nse_calc)\n",
    "\n",
    "        # print(f\"{basinid} {nnse}\")\n",
    "        if i % 100 == 0:\n",
    "            print(f\"{i} / {len(filelist)}\")\n",
    "\n",
    "        # SAVE IN PROPER FORMAT\n",
    "        basinlist.append(basinid)\n",
    "        outnnselist.append(nnse)\n",
    "        \n",
    "    return basinlist, outnnselist, outstruct_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec4642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\anaconda3\\envs\\SI_2022_Test\\lib\\site-packages\\geopandas\\geodataframe.py:1483: FutureWarning: Passing 'suffixes' which cause duplicate columns {'gauge_id_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  result = DataFrame.merge(self, *args, **kwargs)\n",
      "C:\\Users\\franc\\anaconda3\\envs\\SI_2022_Test\\lib\\site-packages\\geopandas\\geodataframe.py:1483: FutureWarning: Passing 'suffixes' which cause duplicate columns {'gauge_id_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  result = DataFrame.merge(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/franc/Downloads/dl//data/hourly_performances/CFE.csv\n",
      "C:/Users/franc/Downloads/dl//data/hourly_performances/linear.csv\n",
      "C:/Users/franc/Downloads/dl//data/hourly_performances/LSTM.csv\n",
      "C:/Users/franc/Downloads/dl//data/hourly_performances/nwm.csv\n",
      "Not weighting in 26 of 495 basins, partial weighting in 302\n",
      "0 / 495\n",
      "100 / 495\n"
     ]
    }
   ],
   "source": [
    "basins, nnse, outstruct = getWeightedFit(rfargs = {\"n_estimators\": 15}, weightparams={\"threshold\":0.2, \"n\":1, \"softmaxflag\": False})\n",
    "\n",
    "camels_df, inputdataset, outputdataset, testvalues, test_modelno, test_modellist, featureimportance, metrics, trainlists = outstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485d3c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = 3\n",
    "n_folds = 5\n",
    "topn = 4\n",
    "width = .4\n",
    "\n",
    "# -------------EXTREMELY IMPORTANT------------------------------------------- \n",
    "# DEFINE THE STARTING INDICES OF THESE LISTS AS THE SAME AS SHOWN IN THE CODE\n",
    "# BLOCK ABOVE (ie, FIRST COLUMN = 0)\n",
    "cfe_i = 0\n",
    "lstm_i = 1\n",
    "nwm_i = 2\n",
    "\n",
    "cfe_idx = np.arange(cfe_i, n_models*n_folds, n_models)\n",
    "lstm_idx = np.arange(lstm_i, n_models*n_folds, n_models)\n",
    "nwm_idx = np.arange(nwm_i, n_models*n_folds, n_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ff6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "\n",
    "def getList(r, ax, c, topn=5):\n",
    "\n",
    "    features = featureimportance[0].shape[0] # NUMBER OF FEATURES\n",
    "    sum = np.zeros((features, ))\n",
    "    ss = np.zeros((features, ))\n",
    "    for i in r:\n",
    "        # POOL MEANS AND STANDARD DEVIATIONS:\n",
    "        # - GROUP MEAN IS MEAN OF ALL MEANS \n",
    "        # - GROUP STD IS DEFINED BY SQRT(SUM(STDs^2)), SINCE ALL SAMPLE SIZES ARE EQUAL\n",
    "        currdf = featureimportance[i]\n",
    "        sum = sum + np.abs(currdf[str(i) + \"_mean\"].to_numpy()).T\n",
    "        ss =  ss + currdf[str(i) + \"_std\"].to_numpy().T\n",
    "\n",
    "    means = sum / len(featureimportance)\n",
    "    means = means/means.sum() * 100 # NORMALIZE TO PERCENT\n",
    "    \n",
    "    std = np.sqrt(ss)  \n",
    "    \n",
    "    ind = np.argsort(means)[-topn:]\n",
    "    \n",
    "    labels = featureimportance[0].index.values[ind]\n",
    "    selmeans = means[ind]\n",
    "    \n",
    "    # REVERSE TO SHOW IN DESCENDING ORDER\n",
    "    #selmeans = selmeans[::-1]\n",
    "    #labels = labels[::-1]\n",
    "    \n",
    "    ax.barh(np.arange(selmeans.shape[0]), selmeans, color=c)\n",
    "    ax.set_yticks(np.arange(selmeans.shape[0]))\n",
    "    ax.set_yticklabels(labels, fontsize=12)\n",
    "    ax.set_xlim((0, 90))\n",
    "    ax.set_xlabel(\"Perc. Variable Importance\")\n",
    "    \n",
    "    return ax\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "figs, axs = plt.subplots(1,3, constrained_layout=True, facecolor=\"white\")\n",
    "\n",
    "\n",
    "figs.suptitle('Variable Importance via RFR Permutation (Top 5)', fontsize=18, x=0.55)\n",
    "axs[0] = getList(lstm_idx, axs[0], 'blue')\n",
    "axs[0].set_title(\"LSTM\")\n",
    "axs[1] = getList(cfe_idx, axs[1], 'red')\n",
    "axs[1].set_title(\"CFE\")\n",
    "axs[2] = getList(nwm_idx, axs[2], 'green')\n",
    "axs[2].set_title(\"NWM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40ea52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_trainr2  = np.array(metrics[0])[lstm_idx]\n",
    "lstm_testr2   = np.array(metrics[1])[lstm_idx]\n",
    "lstm_trainmse = np.array(metrics[2])[lstm_idx]\n",
    "lstm_testmse  = np.array(metrics[3])[lstm_idx]\n",
    "\n",
    "\n",
    "cfe_trainr2  = np.array(metrics[0])[cfe_idx]\n",
    "cfe_testr2   = np.array(metrics[1])[cfe_idx]\n",
    "cfe_trainmse = np.array(metrics[2])[cfe_idx]\n",
    "cfe_testmse  = np.array(metrics[3])[cfe_idx]\n",
    "\n",
    "nwm_trainr2  = np.array(metrics[0])[nwm_idx]\n",
    "nwm_testr2   = np.array(metrics[1])[nwm_idx]\n",
    "nwm_trainmse = np.array(metrics[2])[nwm_idx]\n",
    "nwm_testmse  = np.array(metrics[3])[nwm_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ff793f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prettify(ax, title, string):\n",
    "    props = dict(facecolor='white', alpha=0.5)\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel(\"Prediction of NNSE\", fontsize=16)\n",
    "    ax.set_ylabel(\"NNSE Value\", fontsize=16)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=.5, zorder=0)\n",
    "    ax.text(0.05, 0.95, string, transform=ax.transAxes, fontsize=12, verticalalignment='top', bbox=props, zorder=0)\n",
    "    ax.legend(loc=\"lower right\", fontsize=14)\n",
    "    ax.grid()\n",
    "    return ax\n",
    "\n",
    "def getTrain(trainlists):\n",
    "    x, y = trainlists\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    x_cfe = x[cfe_idx,:].flatten()\n",
    "    y_cfe = y[cfe_idx,:,cfe_i].flatten()\n",
    "    \n",
    "    x_lstm = x[lstm_idx].flatten()\n",
    "    y_lstm = y[lstm_idx,:, lstm_i].flatten()\n",
    "    \n",
    "    x_nwm = x[nwm_idx].flatten()\n",
    "    y_nwm = y[nwm_idx,:, nwm_i].flatten()\n",
    "    \n",
    "    return x_cfe, y_cfe, x_lstm, y_lstm, x_nwm, y_nwm\n",
    "\n",
    "pred_cfe, true_cfe, pred_lstm, true_lstm, pred_nwm, true_nwm = getTrain(trainlists)\n",
    "\n",
    "print(pred_cfe.shape)\n",
    "print(true_cfe.shape)\n",
    "\n",
    "cfestr = f\"Mean Train $R^2$: {cfe_trainr2.mean():.3f}\\nMean Test $R^2$: {cfe_testr2.mean():.3f}\\nMean Train RMSE: {np.sqrt(cfe_trainmse.mean()):.3f}\\nMean Test RMSE: {np.sqrt(cfe_testmse.mean()):.3f}\"\n",
    "lstmstr = f\"Mean Train $R^2$: {lstm_trainr2.mean():.3f}\\nMean Test $R^2$: {lstm_testr2.mean():.3f}\\nMean Train RMSE: {np.sqrt(lstm_trainmse.mean()):.3f}\\nMean Test RMSE: {np.sqrt(lstm_testmse.mean()):.3f}\"\n",
    "nwmstr = f\"Mean Train $R^2$: {nwm_trainr2.mean():.3f}\\nMean Test $R^2$: {nwm_testr2.mean():.3f}\\nMean Train RMSE: {np.sqrt(nwm_trainmse.mean()):.3f}\\nMean Test RMSE: {np.sqrt(nwm_testmse.mean()):.3f}\"\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, constrained_layout=True, facecolor=\"white\")\n",
    "\n",
    "axs[0].scatter(pred_cfe, true_cfe, s=2, color=\"green\", alpha=.75, label=\"Training\")\n",
    "axs[0].scatter(testvalues[:, lstm_i], outputdataset['LSTM_nnse'], s=3, color=\"black\", label=\"Testing\")\n",
    "\n",
    "axs[1].scatter(pred_lstm, true_lstm, s=2, color=\"green\", alpha=.75, label=\"Training\")\n",
    "axs[1].scatter(testvalues[:, cfe_i], outputdataset['CFE_nnse'], s=3, color=\"black\", label=\"Testing\")\n",
    "\n",
    "axs[2].scatter(pred_nwm, true_nwm, s=2, color=\"green\", alpha=.75, label=\"Training\")\n",
    "axs[2].scatter(testvalues[:, nwm_i], outputdataset['nwm_nnse'], s=3, color=\"black\", label=\"Testing\")\n",
    "\n",
    "\n",
    "axs[0] = prettify(axs[0], \"LSTM - RFR\", lstmstr)\n",
    "axs[1] = prettify(axs[1], \"CFE - RFR\", cfestr)\n",
    "axs[2] = prettify(axs[2], \"NWM - RFR\", nwmstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ef812",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "target = outputdataset\n",
    "\n",
    "# THIS IS THE BEST PREDICTED MODEL\n",
    "# CALCULATED AS THE MAXIMUM OF THE PREDICTED PERFORMANCES\n",
    "# BEST PRED MODEL = BPM\n",
    "bpm_idx = np.argmax(testvalues, axis=1)\n",
    "bpm_perf = testvalues[np.arange(testvalues.shape[0]), bpm_idx]\n",
    "\n",
    "# THIS IS THE BEST ACTUAL MODEL\n",
    "# CALCULATED AS THE MAXIMUM OF THE ACTUAL PERFORMANCES\n",
    "# BEST ACTUAL MODEL = BAM\n",
    "target_perf = target.to_numpy()\n",
    "bam_idx = np.argmax(target_perf, axis=1)\n",
    "bam_perf = target_perf[np.arange(testvalues.shape[0]), bam_idx]\n",
    "\n",
    "\n",
    "# ACTUAL MODEL PERFORMANCE = AMP\n",
    "amp = target.to_numpy()\n",
    "\n",
    "cfe = amp[:, cfe_i]\n",
    "cfe_est = testvalues[:, cfe_i]\n",
    "\n",
    "nwm = amp[:, nwm_i]\n",
    "nwm_est = testvalues[:, nwm_i]\n",
    "\n",
    "lstm = amp[:, lstm_i]\n",
    "lstm_est = testvalues[:, lstm_i]\n",
    "\n",
    "bestpred_est = testvalues[np.arange(amp.shape[0]), bpm_idx]\n",
    "bestpred_real = amp[np.arange(amp.shape[0]), bpm_idx]\n",
    "\n",
    "bestmodel = bam_perf\n",
    "\n",
    "# perf_models = [cfe_est, cfe, lstm_est, lstm, bestpred_est, bestpred_real, bestmodel]\n",
    "# labs = [\"CFE\\nRFR\", \"CFE\\nActual\", \"LSTM\\nRFR\",\"LSTM\\nActual\", \"BPM\\nRFR\", \"BPM\\nActual\", \"BAM\"]\n",
    "\n",
    "perf_models = [cfe, nwm, lstm, bestpred_real, bestmodel, nnse]\n",
    "labs = [\"CFE\", \"NWM\", \"LSTM\", \"BPM\", \"BAM\", \"WE\"]\n",
    "\n",
    "fig, ax = plt.subplots(facecolor=\"white\")\n",
    "ax.boxplot(perf_models, labels=labs, showmeans=True)\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"NNSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea2f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "perf_models = [bestpred_real, bestmodel, nnse]\n",
    "labs = [\"BPM\", \"BAM\", \"Weighted Ensemble\"]\n",
    "# \n",
    "\n",
    "plt.boxplot(perf_models, labels=labs, showmeans=True)\n",
    "plt.ylabel(\"NNSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1949852",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_ensemble = pd.DataFrame(basins, columns=[\"basin_id\"])\n",
    "perf_ensemble[\"ensemble\"] = nnse\n",
    "\n",
    "\n",
    "bam_df = camels_df[[\"hru_id\"]].copy()\n",
    "bam_df['basin_id'] = bam_df['hru_id'].astype(str).str.zfill(8)\n",
    "bam_df[\"bam\"] = bam_perf\n",
    "bam_df[\"bpm\"] = bestpred_real\n",
    "\n",
    "perf_df = bam_df.merge(perf_ensemble, on=\"basin_id\")\n",
    "\n",
    "perf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7569b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = perf_df\n",
    "perf[\"ensemble_d\"] = perf[\"ensemble\"] - perf[\"bam\"]\n",
    "perf[\"ensemble_p\"] = perf[\"ensemble\"] - perf[\"bpm\"]\n",
    "plt.hist(perf[\"ensemble_d\"], bins=20)\n",
    "print(f'{perf[perf[\"ensemble_d\"] > 0].shape[0]} basins where ensemble outperformed BAM, {perf[perf[\"ensemble_p\"] > 0].shape[0]} where outperformed BPM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acab68a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(unique, counts) = np.unique(bpm_idx, return_counts=True)\n",
    "print(unique)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f4242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(bam_idx, bpm_idx, normalize='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e0087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "camels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db75e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(perf_df[\"ensemble\"].to_numpy() > perf_df[\"bam\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735caeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "\n",
    "ensemblelist = list()\n",
    "lstmlist = list()\n",
    "cfelist = list()\n",
    "nwmlist = list()\n",
    "bpmlist = list()\n",
    "bamlist = list()\n",
    "quantiles = np.arange(0, 1, 0.02)\n",
    "for i in quantiles:\n",
    "    ensemblelist.append(perf_df.ensemble.quantile(i))\n",
    "    bpmlist.append(perf_df.bpm.quantile(i))\n",
    "    lstmlist.append(camels_df.LSTM_nnse.quantile(i))\n",
    "    cfelist.append(camels_df.CFE_nnse.quantile(i))\n",
    "    nwmlist.append(camels_df.nwm_nnse.quantile(i))\n",
    "    bamlist.append(perf_df.bam.quantile(i))\n",
    "\n",
    "    \n",
    "quantiles = quantiles*100\n",
    "plt.plot(quantiles, ensemblelist, \"Orange\",label=\"Weighted Ensemble\")\n",
    "plt.plot(quantiles, lstmlist, \"Blue\", label=\"Long-Short Term Memory\")\n",
    "plt.plot(quantiles, cfelist, \"Red\", label=\"Conceptual Functional Equivalent\")\n",
    "plt.plot(quantiles, nwmlist, \"Green\", label=\"National Water Model\")\n",
    "plt.plot(quantiles, bpmlist, \"Purple\", label=\"Best Predicted Model\")\n",
    "plt.plot(quantiles, bamlist, \"brown\", linestyle=\"--\", label=\"Best Actual Model\")\n",
    "plt.xlabel(\"Percentile\")\n",
    "plt.ylabel(\"NNSE\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df9d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "\n",
    "ensemblelist = list()\n",
    "lstmlist = list()\n",
    "cfelist = list()\n",
    "nwmlist = list()\n",
    "bpmlist = list()\n",
    "quantiles = np.arange(0, 1, 0.02)\n",
    "for i in quantiles:\n",
    "    ensemblelist.append(perf_df.ensemble.quantile(i))\n",
    "    bpmlist.append(perf_df.bpm.quantile(i))\n",
    "    lstmlist.append(camels_df.LSTM_nnse.quantile(i))\n",
    "    cfelist.append(camels_df.CFE_nnse.quantile(i))\n",
    "    nwmlist.append(camels_df.nwm_nnse.quantile(i))\n",
    "\n",
    "    \n",
    "quantiles = quantiles*100\n",
    "\n",
    "fig, ax = plt.subplots(facecolor=\"white\")\n",
    "\n",
    "ax.plot(lstmlist, quantiles, \"Blue\", linewidth=2, label=\"Long-Short Term Memory\")\n",
    "ax.plot(cfelist, quantiles, \"Red\", linewidth=2, label=\"Conceptual Functional Equivalent\")\n",
    "ax.plot(nwmlist, quantiles, \"Green\", linewidth=2, label=\"National Water Model\")\n",
    "ax.plot(ensemblelist, quantiles, \"Orange\", linewidth=2, label=\"Weighted Ensemble\")\n",
    "ax.plot(bpmlist, quantiles, \"brown\", linewidth=2, label=\"Best Predicted Model\")\n",
    "ax.plot(bamlist, quantiles, \"black\", linestyle=\"--\", label=\"Best Actual Model\")\n",
    "ax.set_xlabel(\"NNSE\", fontsize=18)\n",
    "ax.set_ylabel(\"Percentile\", fontsize=18)\n",
    "ax.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb88e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "camels_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c52bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettify(ax, title, string):\n",
    "    props = dict(facecolor='white', alpha=0.5)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Prediction of NNSE\")\n",
    "    ax.set_ylabel(\"NNSE Value\")\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=.5, zorder=0)\n",
    "    ax.text(0.05, 0.95, string, transform=ax.transAxes, fontsize=10, verticalalignment='top', bbox=props, zorder=0)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    ax.grid()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc91d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3)\n",
    "\n",
    "axs[0].plot(camels_df[\"area_gages2\"], camels_df[\"LSTM_nnse\"], '.k', markersize=2)\n",
    "axs[0].plot(bin_edges[1:], bin_means, '-r')\n",
    "bin_means, bin_edges, binnumber = stats.binned_statistic(camels_df[\"area_gages2\"], camels_df[\"LSTM_nnse\"], statistic='mean', bins=15)\n",
    "axs[1].plot(camels_df[\"area_gages2\"], camels_df[\"CFE_nnse\"], '.k', markersize=2)\n",
    "bin_means, bin_edges, binnumber = stats.binned_statistic(camels_df[\"area_gages2\"], camels_df[\"CFE_nnse\"], statistic='mean', bins=15)\n",
    "axs[1].plot(bin_edges[1:], bin_means, '-r')\n",
    "axs[2].plot(camels_df[\"area_gages2\"], camels_df[\"nwm_nnse\"], '.k', markersize=2)\n",
    "bin_means, bin_edges, binnumber = stats.binned_statistic(camels_df[\"area_gages2\"], camels_df[\"nwm_nnse\"], statistic='mean', bins=15)\n",
    "axs[2].plot(bin_edges[1:], bin_means, '-r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1405e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 15)\n",
    "\n",
    "def myplot(ax, name, model):\n",
    "    bin_means, bin_edges, binnumber = stats.binned_statistic(camels_df[name], camels_df[model], statistic='mean', bins=15)\n",
    "    bin_edges_spec = (bin_edges[1:] + bin_edges[:-1]) / 2\n",
    "    ax.plot(camels_df[name], camels_df[model], '.k', markersize=2)\n",
    "    ax.plot(bin_edges_spec, bin_means, '-r')\n",
    "    ax.set_ylabel(\"NNSE\")\n",
    "    ax.set_xlabel(name)\n",
    "    return ax\n",
    "\n",
    "def plotVariables(axs, name):\n",
    "    \n",
    "    axs[0] = myplot(axs[0], name, \"LSTM_nnse\")\n",
    "    axs[1] = myplot(axs[1], name, \"CFE_nnse\")\n",
    "    axs[2] = myplot(axs[2], name, \"nwm_nnse\")\n",
    "    return axs\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(4,3)\n",
    "axs[0, :] = plotVariables(axs[0, :], \"area_gages2\")\n",
    "axs[1, :] = plotVariables(axs[1, :], \"frac_snow\")\n",
    "axs[2, :] = plotVariables(axs[2, :], \"p_mean\")\n",
    "axs[3, :] = plotVariables(axs[3, :], \"aridity\")\n",
    "\n",
    "cols = [\"LSTM\", \"CFE\", \"NWM\"]\n",
    "rows = [\"Basin Area\", \"Snow Fraction\", \"Precipitation Mean\", \"Aridity\"]\n",
    "\n",
    "for ax, col in zip(axs[0], cols):\n",
    "    ax.set_title(col)\n",
    "\n",
    "for ax, row in zip(axs[:,0], rows):\n",
    "    ax.set_ylabel(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8eed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,3)\n",
    "axs[0, :] = plotVariables(axs[0, :], \"low_prec_dur\")\n",
    "axs[1, :] = plotVariables(axs[1, :], \"elev_mean_x\")\n",
    "axs[2, :] = plotVariables(axs[2, :], \"silt_frac\")\n",
    "axs[3, :] = plotVariables(axs[3, :], \"sand_frac\")\n",
    "\n",
    "cols = [\"LSTM\", \"CFE\", \"NWM\"]\n",
    "rows = [\"Low Precipitation\", \"Elevation Mean\", \"Silt Fraction\", \"Sand Fraction\"]\n",
    "\n",
    "for ax, col in zip(axs[0], cols):\n",
    "    ax.set_title(col)\n",
    "\n",
    "for ax, row in zip(axs[:,0], rows):\n",
    "    ax.set_ylabel(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a68e365148b5d9c09240538ac88f218033b21a0261749929a8c66fd3e96bdec5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
